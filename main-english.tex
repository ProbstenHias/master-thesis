% !TeX spellcheck = en-US
% !TeX encoding = utf8
% !TeX program = pdflatex
% !BIB program = biber
% -*- coding:utf-8 mod:LaTeX -*-
% !TEX root = ./main-english.tex

% vv  scroll down to line 200 for content  vv


\let\ifdeutsch\iffalse
\let\ifenglisch\iftrue
\input{pre-documentclass}
\documentclass[
  % fontsize=11pt is the standard
  a4paper,  % Standard format - only KOMAScript uses paper=a4 - https://tex.stackexchange.com/a/61044/9075
  twoside,  % we are optimizing for both screen and two-side printing. So the page numbers will jump, but the content is configured to stay in the middle (by using the geometry package)
  bibliography=totoc,
  %               idxtotoc,   %Index ins Inhaltsverzeichnis
  %               liststotoc, %List of X ins Inhaltsverzeichnis, mit liststotocnumbered werden die Abbildungsverzeichnisse nummeriert
  headsepline,
  cleardoublepage=empty,
  parskip=half,
  %               draft    % um zu sehen, wo noch nachgebessert werden muss - wichtig, da Bindungskorrektur mit drin
  draft=false
]{scrbook}
\input{config}


\usepackage[
  title={Implementing Variational Quantum Algorithms as Compositions of Reusable Microservice-based Plugins},
  author={Matthias Weilinger},
  type=master,
  institute=iaas, % or other institute names - or just a plain string using {Demo\\Demo...}
  course={Informatik},
  examiner={Prof.\ Dr.\ Dr.\ h.\ c.\ Frank Leymann},
  supervisor={M.Sc.\ Philipp Wundrack,\\M.Sc.\ Fabian Bühler},
  startdate={April 19, 2023},
  enddate={October 19, 2023}
]{scientific-thesis-cover}

\input{acronyms}

\makeindex

\begin{document}

%tex4ht-Konvertierung verschönern
\iftex4ht
  % tell tex4ht to create picures also for formulas starting with '$'
  % WARNING: a tex4ht run now takes forever!
  \Configure{$}{\PicMath}{\EndPicMath}{}
  %$ % <- syntax highlighting fix for emacs
  \Css{body {text-align:justify;}}

  %conversion of .pdf to .png
  \Configure{graphics*}
  {pdf}
  {\Needs{"convert \csname Gin@base\endcsname.pdf
      \csname Gin@base\endcsname.png"}%
    \Picture[pict]{\csname Gin@base\endcsname.png}%
  }
\fi

%\VerbatimFootnotes %verbatim text in Fußnoten erlauben. Geht normalerweise nicht.

\input{commands}
\pagenumbering{arabic}
\Titelblatt

%Eigener Seitenstil fuer die Kurzfassung und das Inhaltsverzeichnis
\deftriplepagestyle{preamble}{}{}{}{}{}{\pagemark}
%Doku zu deftriplepagestyle: scrguide.pdf
\pagestyle{preamble}
\renewcommand*{\chapterpagestyle}{preamble}



%Kurzfassung / abstract
%auch im Stil vom Inhaltsverzeichnis
\ifdeutsch
  \section*{Kurzfassung}
\else
  \section*{Abstract}
\fi

<Short summary of the thesis>

\cleardoublepage


% BEGIN: Verzeichnisse

\iftex4ht
\else
  \microtypesetup{protrusion=false}
\fi

%%%
% Literaturverzeichnis ins TOC mit aufnehmen, aber nur wenn nichts anderes mehr hilft!
% \addcontentsline{toc}{chapter}{Literaturverzeichnis}
%
% oder zB
%\addcontentsline{toc}{section}{Abkürzungsverzeichnis}
%
%%%

%Produce table of contents
%
%In case you have trouble with headings reaching into the page numbers, enable the following three lines.
%Hint by http://golatex.de/inhaltsverzeichnis-schreibt-ueber-rand-t3106.html
%
%\makeatletter
%\renewcommand{\@pnumwidth}{2em}
%\makeatother
%
\tableofcontents

% Bei einem ungünstigen Seitenumbruch im Inhaltsverzeichnis, kann dieser mit
% \addtocontents{toc}{\protect\newpage}
% an der passenden Stelle im Fließtext erzwungen werden.

\listoffigures
\listoftables

%Wird nur bei Verwendung von der lstlisting-Umgebung mit dem "caption"-Parameter benoetigt
%\lstlistoflistings
%ansonsten:
\ifdeutsch
  \listof{Listing}{Verzeichnis der Listings}
\else
  \listof{Listing}{List of Listings}
\fi

%mittels \newfloat wurde die Algorithmus-Gleitumgebung definiert.
%Mit folgendem Befehl werden alle floats dieses Typs ausgegeben
\ifdeutsch
  \listof{Algorithmus}{Verzeichnis der Algorithmen}
\else
  \listof{Algorithmus}{List of Algorithms}
\fi
%\listofalgorithms %Ist nur für Algorithmen, die mittels \begin{algorithm} umschlossen werden, nötig

% Abkürzungsverzeichnis
\printnoidxglossaries

\iftex4ht
\else
  %Optischen Randausgleich und Grauwertkorrektur wieder aktivieren
  \microtypesetup{protrusion=true}
\fi

% END: Verzeichnisse


% Headline and footline
\renewcommand*{\chapterpagestyle}{scrplain}
\pagestyle{scrheadings}
\pagestyle{scrheadings}
\ihead[]{}
\chead[]{}
\ohead[]{\headmark}
\cfoot[]{}
\ofoot[\usekomafont{pagenumber}\thepage]{\usekomafont{pagenumber}\thepage}
\ifoot[]{}


%% vv  scroll down for content  vv %%































%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Main content starts here
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Notes what I have done so far}
\begin{itemize}
  \item Added recursive parsing of the plugin folders so that subfolders are also parsed
  \item created a callable plugin that gets the data parsed from its invoker via the database
  \item created a invoker that calls the callable plugin
  \item user can now select a plugin from the list of callable plugins, the list is narrowed down to the plugins that are compatible via the tag field
  \item creating a method to get the plugin name from the plugin URL
  \item made the callee plugin to multistep, to demonstrate that any amount of steps can be done in invoked plugin
  \item started with an optimizer plugin that gives the first frontend for the user to select the objective-function-plugin
  \item create an objective-function-plugin that takes means squared error as an objective function
  \item todo: creating a method to get the plugin metadata from the plugin URL (this is needed in order to get the entry points of the plugin)
  \item identified three key problems:
  \begin{itemize}
    \item Reliable way to pass a callback function to the callee plugin
    \item A way to get a list of interaction endpoints of the callee plugin
    \item A way to get the plugin metadata from the plugin URL
  \end{itemize}
  \item 19.05: I am currently working on a big problem
  \begin{itemize}
    \item I have the optimizer plugin which should call the objective-function-plugin so that it can ask the user for the hyperparameters of the objective function
    \item For that reason I need to add a next step as a celery task.
    \item The thing is i don't want to handle the next task like other multistep plugins where they share a db id since the objective-function-plugin should be able to stand on its own.
    \item Therefore, I pass a callback function to the objective-function-plugin which it should call when it is done with the setup.
    \item works all fine like that
    \item The problem right now is how i call the objective-function-plugin from the optimizer plugin
    \item I need to add it as a step, which is usually done via the add\_step celery task
    \item This task though needs a db\_id which I don't want to add.
    \item When adding none it works to call the objective-function-plugin and its also possbile to call the callback function
    \item but the problem is that with the add\_step task the celery task is not called asyncronously
    \item therefore when the callback function is called the optimizer plugin is not yet finished with the add\_step task
    \item usually one would go in the called multistep and do a clear\_previous\_steps call to make sure that the previous steps are finished
    \item but this call does not work since the objective-function-plugin does not have a db\_id
    \item thinking right now....
    \item maybe we can finish the task in the callback function of the optimizer plugin?
    \item Still 19.05 here we are again
    \item I have now a working solution for the problem
    \item the proposed solution of clearing the previous steps in the callback function did work
    \item the problem was that i forgot to add the call db\_task.save(cammit=True) in the callback function
    \item this is needed to save the changes to the database without it the cleared variable is not saved
  \end{itemize}
  \item 20.05: Today we give the objective-function-plugin the ability to calculate the loss function
  \begin{itemize}
    \item On callback we give the optimizer plugin the url of the calculateLoss function url
    \item The optimizer plugin then calls the calculateLoss function
  \end{itemize}
  \item 22.05: we continue with the upper
  \begin{itemize}
    \item it is now possible to calculate the loss function
    \item we simply call the calculation enpoint with a post request
    \item we pass all the necessary data in the body of the request
    \item we have a special schema for that
    \item current problem: passing the data to the minimize function of scipy.optimize
    \item we have the hyperparameters as a dict to keep it as generic as possible
    \item but the minimize function needs the hyperparameters as a list
    \item and also the loss function needs the hyperparameters as a dict, so lets see how we can solve this
    \item we maybe did it by just passing the hyperparameters as a dict to both of the functions
    \item now we have the problem that the content type of the input file is not correctly set by postman
    \item we just change the code to accept the content type but lets not forget to change it back
  \end{itemize}
  \item 23.05: today we do some cleanup
  \begin{itemize}
    \item make the import relative so that it works with the docker container
    \item remove all no ops tasks
  \end{itemize}
  \item 02.06:
  \begin{itemize}
    \item we want to skip the optimizer UI since we do not need any more input data
    \item tried to set the cleared value of the created step to true, but it did not work, since only the process step is started is by clicking submit in the ui
    \item trying to chain the tasks directly in the callback function, which works
  \end{itemize}
  \item 05.06:
  \begin{itemize}
    \item now I want to call the objective-function-plugin via the entry points that I get through the metadata, this is needed to make the plugins more generic
    \item I have a problem where the shared schemas can not be imported since the NumPy package cannot be found, added the NumPy package to the requirements for the opt plugin, but this did not solve the problems
    \item maybe this will be solved by creating a coordinator plugin that lives in the top level of the plugin folder
  \end{itemize}
  \item 12.06:
  \begin{itemize}
    \item Creating a top level coordinator plugin was not the solution. If an init file is present no further plugins will be loaded from the folder
    \item the shared schemas are now part of the coordinator plugin
    \item Created a new infrastructure for the plugins with a coordinator plugin (diagram will be needed)
    \item today we solve the following problem:
    \item coordinator waits for the optimizer plugin to finish and writes the result to a file
    \item for this the coordinator polls the task api to check if the minimizer task is finished
    \item when it is it writes the result to a file
    \item I should move the callback URL away from the query parameters to the body of the request, maybe to the form
    \item next I should read about how neural networks work and how to minimize them
  \end{itemize}
  \item 13.06:
  \begin{itemize}
    \item i have made a decision on how to handle the callback url from the ui to the processing endpoint
    \item until now the callback url was passed as a query parameter
    \item now i want to pass it into the form that is rendered by the UI
    \item it should be a hidden field
    \item i have to make and change so that i can pass multiple schemas to the render function and set which fields should be hidden
  \end{itemize}
  \item 16.06:
  \begin{itemize}
    \item when an invoked plugin now makes a callback to its invoker it only passes back the endpoint for the calculation endpoint.
    \item it does not pass any hyperparameters back since it should own the hyperparameters and not the invoker
    \item i now want to have a look of how loss functions are called in python and how hyperparameters are passed to them
    \item with this information I want to create interaction endpoints for the objective-function-plugin that are completely generic, i.e. the hyperparameters are passed to the endpoint as a dict
    \item as an example of how a generic method could look like i will have a look at the scipy.optimize.minimize function
    \item I now interaction endpoints as and additional list to entry points
  \end{itemize}
  \item 25.06:
  \begin{itemize}
    \item i have added a functionality where I use the blinker library to create a signal that is emitted when the status of a task changes
    \item this is used by the coordinator plugin to check if the minimization task is finished
    \item the coordinator plugin passes the callback URL to the minimization calculation endpoint
    \item this endpoint registers the URL to the db
    \item the signal handlers makes a post request to this URL when the status of the task changes
    \item I have moved all shared schemas into a separate folder
    \item I have moved all utilities concerning plugin interactions into a separate folder
  \end{itemize}
  \item 26.06:
  \begin{itemize}
    \item I developed a way to pass any amount of parameters to the processing endpoint of the invoked plugin UI
    \item I added an interaction endpoint that is used to invoke the invoked plugin
    \item this interaction endpoint allows any number of parameters
    \item the endpoint saves these parameters to the database
    \item it then adds the entry points of the invoked plugin as a step
    \item it passes the processing URL with the db id as a query parameter to the invoked plugin
    \item the invoked plugin then calls the processing endpoint with the db id as a query parameter
    \item here it starts a new db task with the arguments that were passed to the invoked plugin
  \end{itemize}
\end{itemize}


\chapter{Define the plugins}
\begin{itemize}
  \item \textbf{ObjectiveFunction}: This plugin should have the following steps
  \begin{itemize}
    \item \textbf{ /get hyperparameterUI }: This step should let the user select the hyperparameters of the objective function
    \item \textbf{ /post ObjectiveFunctionSetup}: This step should setup the objective function with set a database id for future reference of the parameter.
    Then it should store the following information to the database:
    \begin{itemize}
      \item hyperparameters
      \item more stuff?? %%% TODO specify what more stuff
    \end{itemize}
    Then it should call the optimizer callback function to indicate that the setup is done. Pass the url of the calculateLoss function as a parameter.
    \item \textbf{ /post CalculateLoss (dbID) }: this step should trigger the calculation of the loss function and should return it.
  \end{itemize}
  \item \textbf{Optimizer}: This plugin should have the following steps:
    \begin{itemize}
      \item \textbf{ /get setup UI }: Let the user select the objective-function-plugin, dataset, target variable, and the optimization algorithm
      \item \textbf{ /post setup }: This step should setup the optimizer with set a database id for future reference of the parameter.
      Then it should call the objective function entry point to setup the objective function. Pass the url of the optimizer callback function as a parameter.
      \item \textbf{ /post callback }: This endpoint should be called by the objective-function-plugin to indicate that the setup is done.
      It should then start the optimization process.
      \item \textbf{ /post optimize }: This step should trigger the optimization process.
      It should loop the optimization function until a stop condition is met.
      In each iteration it should call the objective-function-plugin to calculate the loss function.
    \end{itemize}
\end{itemize}

\chapter{Introduction}
\label{chap:introduction}

\chapter{Background}
\label{chap:background}

The study of QHana and its advanced plugin interactions is rooted in a set of foundational principles that underpin its functionality.
This chapter aims to offer a comprehensive introduction to these principles, encompassing key areas such as optimization algorithms, quantum computing, \glspl{vqa}, REST, and the core architecture of QHana.
By delving into these foundational topics, readers will gain the necessary context to understand the innovative approaches adopted in this thesis.

\section{QHana}
\label{sec:qhana}

QHana, an acronym for Quantum Humanities Analysis tool, was conceived as a specialized application in the domain of Digital Humanities (DH).
Its primary design offers users a platform to explore various machine learning algorithms on designated datasets.
While the primary vision of QHana was to assess the potential advantages of quantum algorithms within the DH community, the rise and cloud availability of quantum computers further underscore its relevance and timeliness.

QHana is designed to be extensible, allowing the integration of new data sources and quantum algorithms as plugins.
However, plugins are built for specific applications, limiting their reusability in other contexts.
Moreover, plugins for an application have to be developed in the same programming language as the application.
Even if a plugin can be reused in another application, its UI has to adapt to the new application, otherwise users may fail to understand the plugin's functionality.
To address this limitation, QHana is built on a novel concept of Reusable Microservice-based Plugins (RAMPs).
This allows microservices with an integrated UI to be used as plugins by multiple applications, enhancing the reusability of the plugins across different applications \cite{Buehler2022}.

Central to this thesis is the integration of \glspl{vqa}
The envisioned approach allows for plugins to interact and collaborate, enabling the implementation of \glspl{vqa} as modular components within QHana.

\section{Quantum Computing}
\label{sec:quantumComputing}
Quantum computing is a cutting-edge field that exploits the principles of quantum mechanics to process information.
Unlike classical computers that use bits (0s and 1s) to store and process information, quantum computers use quantum bits, or \emph{qubits}.
Qubits, through the phenomena of superposition and entanglement, can exist in multiple states at once and be correlated with each other in ways that classical bits cannot \cite{Nielsen2010}.

Superposition allows a qubit to be in a state that is a combination of both 0 and 1, with a certain probability for each.
This property enables quantum computers to perform many calculations simultaneously, vastly increasing their potential computational power.
Entanglement, on the other hand, allows qubits that are entangled to be intimately linked regardless of the distance separating them.
A change in the state of one will instantaneously affect the state of the other, a phenomenon that Einstein famously called spooky action at a distance \cite{Einstein1935}.
This property is essential for many quantum algorithms, quantum error correction, and quantum teleportation, making it a fundamental resource in quantum information processing \cite{Nielsen2010,Preskill1998}.


\section{Variational Quantum Algorithms}
\label{sec:variationalQuantumAlgorithms}

\glspl{vqa} bring together the principles of quantum computing and optimization in a unique and powerful way.
They are a class of hybrid quantum-classical algorithms that leverage the strengths of both quantum and classical computing to solve complex problems \cite{McClean2016}.

The main concept of \glspl{vqa} is to use a sequence of quantum operations (a "quantum circuit") controlled by certain parameters.
These parameters are adjusted using classical optimization techniques with the aim of solving a specific problem.
This problem, in many cases, involves finding the lowest energy state, or "ground state", of a quantum system, a problem that maps to finding the minimum of a particular function \cite{Peruzzo2013}.

By leveraging classical optimization algorithms, \glspl{vqa} become more resistant to quantum errors, as the majority of the computation is performed on a classical computer.
This combination of quantum and classical resources makes \glspl{vqa} a promising type of algorithm for near-term quantum devices \cite{Moll2017}.


\section{Optimization Algorithms}
\label{sec:optimizationAlgorithms}
Optimization is a powerful tool that's ubiquitous in various scientific and technological domains.
At its core, optimization is about finding the best solution from a set of possible choices.
This section provides a snapshot of optimization's fundamental principles, paving the way for its deeper exploration in the context of \glspl{vqa} and finally microservice based \glspl{vqa}.

\subsection{Objective Functions}
\label{subsec:objectiveFunctions}
\glspl{of} are fundamental to optimization problems, underpinning a myriad of computational algorithms and models.
Depending on specific requirements, the aim might be to minimize or maximize these functions.
Notably, within the realm of \glspl{vqa}, the focus is primarily on function minimization \cite{Weinan2017}.

The core inputs to a \gls{of} typically encompass data points (denoted as $x$), corresponding labels or outcomes (represented by $y$), and a set of parameters or weights (often symbolized by $\theta$ or $w$).
These parameters dictate how the model responds to the input data and makes its predictions.
Additionally, certain \glspl{of} may also include hyperparameters as input, which control the behavior and complexity of the model.
In the context of optimization problems, the role of an \gls{of} is to capture both the problem we're attempting to solve and the strategy by which we're trying to solve it.
It provides a measure of the 'goodness' or 'fitness' of our current solution or parameters, and the aim is to adjust these parameters to improve this measure.

One example of an \gls{of} is the Lasso (Least Absolute Shrinkage and Selection Operator) Loss function.
The Lasso loss function is represented as:
\[
L(Y, X, W, \lambda) = ||Y - XW||^2_2 + \lambda ||W||_1
\]
In this equation:

\begin{itemize}
  \item \(Y\) is the vector of observed values.
  \item \(X\) is the matrix of input data points.
  \item \(W\) is the vector of weights, the parameters of the model.
  \item \(\lambda\) is the regularization parameter, a non-negative hyperparameter.
\end{itemize}

This function consists of two terms:
\begin{enumerate}
  \item The first term \(||Y - XW||^2_2\) is the mean squared error between the predicted and actual outcomes.
  It measures the discrepancy between the model's predictions and the true values.
  \item The second term \(\lambda ||W||_1\) is a regularization term, where \(||W||_1\) represents the L1 norm (sum of absolute values) of the weight vector.
  This term penalizes the absolute size of the coefficients, encouraging them to be small.
\end{enumerate}
The hyperparameter \(\lambda\) governs the trade-off between these two terms.
When \(\lambda = 0\), the \gls{of} reduces to ordinary least squares regression, and the weights are chosen to minimize the mean squared error alone.
As \(\lambda\) increases, more weight is given to the regularization term, and the solution becomes more sparse (i.e., more of the weights are driven to zero).
This can help to prevent overfitting by effectively reducing the complexity of the model \cite{ShalevShwartz2014}

\subsection{Minimization Functions}
\label{subsec:minimizationFunctions}
Minimization functions, often referred to as optimization algorithms, play a pivotal role in a vast array of computational models and algorithms.
In essence, they serve to iteratively enhance the parameters of a model to reduce the value of the \gls{of}.
The goal of these minimization functions is to find the optimal set of parameters that yield the lowest possible value of the \gls{of} within the constraints of the problem \cite{Nocedal2006}.

The process of optimization involves a search through the parameter space.
This search can be visualized as navigating a landscape of hills and valleys, with each point in the landscape corresponding to a different set of parameters, and the height at each point representing the value of the \gls{of}.
The goal of the minimization function is to find the lowest point in this landscape, corresponding to the minimum value of the \gls{of} \cite{Goodfellow2017}.

The core inputs to a minimization function are the initial parameters of the model or weights (denoted as \(\theta\) or \(w\)),
the \gls{of} that needs to be minimized, and the gradients of the \gls{of} with respect to the parameters.
Additionally, certain minimization functions may also include hyperparameters as input, which control the behavior and complexity of the optimization process \cite{Virtanen2020}.
For instance, the learning rate is a typical hyperparameter that determines the step size in each iteration of the optimization process.

There are numerous minimization functions used in computational problems, each with its own strengths and weaknesses.
These range from simple methods such as gradient descent, to more complex ones such as the Newton's method, stochastic gradient descent (SGD), RMSprop, and Adam.

One of the most fundamental and widely used minimization functions is the Gradient Descent.
To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.

The update rule of gradient descent is given as:

\[
\theta_{t+1} = \theta_t - \alpha \nabla F(\theta_t)
\]

In this formula:

\begin{itemize}
  \item \(\theta_{t+1}\) represents the parameters at the next time step.
  \item \(\theta_t\) represents the current parameters.
  \item \(\alpha\) is the learning rate, a positive scalar determining the size of the step.
  \item \(\nabla F(\theta_t)\) is the gradient of the \gls{of}.
\end{itemize}

Here, the \gls{of} \(F\) is assumed to be a differentiable function.
The gradient \(\nabla F(\theta_t)\) provides the direction of the steepest ascent at the point \(\theta_t\), and \(-\nabla F(\theta_t)\) provides the direction of steepest descent.
By taking a step in this direction, we move towards the minimum of the function.

The size of the steps taken is determined by the learning rate \(\alpha\), which is a hyperparameter that must be set before the learning process begins.
The learning rate controls how fast or slow we move towards the optimal weights.
If the learning rate is very large, we may skip the optimal solution.
If it is too small, we may need too many iterations to converge to the best values.

The choice of minimization function can significantly influence the efficiency and success of the optimization process.
While some minimization functions may perform well on certain problems, they may not yield similar results on others.
Therefore, understanding the underlying mechanisms of these functions and their suitability to the specific problem at hand is crucial.


\section{RESTful API Design}
In the evolving landscape of software design, microservices have emerged as a preferred architectural style, prized for their modularity, scalability, and independent deployability.
At the heart of QHAna's design is a microservices-based plugin approach, which facilitates its dynamic and extensible nature.
Central to the orchestration of these microservices is the application of RESTful API design.
Representational State Transfer (REST) is an architectural style that sets forth constraints for creating web services.
RESTful APIs, built upon these constraints, are pivotal in ensuring seamless communication between individual microservices, thereby enabling efficient data exchange and service integration.

For those seeking a deeper dive into the intricacies of RESTful design in microservices architectures, influential works by Fielding \cite{Fielding2000} and practical insights by Richardson and Amundsen \cite{Richardson2013} are recommended.

\chapter{Problem Statement and Objectives}
\label{chap:problem}

Optimization algorithms, with their ability to find the best possible solution from a set of feasible solutions, play a pivotal role in numerous computational domains.
\glspl{vqa} are a subset of these algorithms that leverage quantum computing principles, particularly in the realm of \glspl{of} and minimization techniques.
However, the true potential of optimization, and by extension \glspl{vqa}, is often hindered by rigid platforms where the components of these algorithms are tightly integrated, limiting adaptability and innovation.

QHana, with its unique environment tailored for experimenting with a myriad of machine learning and quantum algorithms, presents an opportunity to redefine this paradigm.
Yet, its current architecture does not fully exploit the modular benefits that can be achieved by decoupling the components of optimization algorithms.
Furthermore, while developing this modular framework, it's essential to allow for plugins to interact with each other.
This interaction-centric concept, once established, can be universally applied across QHana, not just for optimization but for any scenario where plugin interaction is required.

\textbf{Problem Statement:}
How can we design and implement a modular framework within QHana that allows components of optimization algorithms, specifically \glspl{of} and minimization functions, to be encapsulated as distinct, interchangeable plugins?
Furthermore, how can these plugins, especially in the context of \glspl{vqa}, be structured to communicate and collaborate seamlessly?

This problem encompasses several challenges:

\begin{itemize}
    \item \textbf{Communication:} Establishing a robust communication mechanism that enables interaction, data sharing, and collaboration among these plugins.
    \item \textbf{Interchangeability:} Designing a system where different \gls{of} and minimization plugins can be effortlessly swapped, ensuring adaptability in optimization and \glspl{vqa}.
    \item \textbf{Standardization:} Implementing a consistent interface for these plugins, ensuring uniformity and compatibility across various \gls{of} and minimization plugins.
    \item \textbf{User Experience:} Providing an intuitive environment where users can easily select, interchange, and experiment with different optimization components tailored to their needs and provide developers with an extensible framework to build new minimization and \gls{of} plugins.
\end{itemize}

Addressing this problem is essential to enhance the capabilities of QHana, transforming it into a dynamic, adaptable, and user-centric platform for optimization and VQAs.
The subsequent sections of this thesis will delve into the methodologies, implementations, and evaluations related to this problem.

\chapter{Related Work}

\cite{Beisel2023} \cite{Beisel2023a} \cite{Thullier2021}

\chapter{Methodology}
\label{chap:methodology}
\section{Conceptual Framework}
\label{sec:conceptualFramework}

This section outlines the theoretical and conceptual groundwork that anchors the methodology for this thesis.
The framework is rooted in the principles of modularity, interactivity, and adaptability in the context of plugin-based architectures and optimization algorithms.

\subsection{Plugin-Based Architecture in QHana}
QHana, with its design centered on the Digital Humanities, provides an extensible platform for experimenting with various algorithms.
QHana's architecture predominantly revolves around the concept of RAMPs.
The objective is to leverage QHana's inherent modularity by enabling components of optimization algorithms to function as distinct, interchangeable plugins.
This brings us to the significance of modularity in optimization.

\subsection{Significance of Modularity in Optimization}
When VQAs are designed with modular components, it allows for increased flexibility.
Specifically, having distinct \glspl{of} and minimization functions means parts of the algorithm can be adjusted or replaced seamlessly.
This reflects the goals of modularity and flexibility intrinsic to QHana's design.

\subsection{Interactivity Between Plugins}
Interactivity in QHana encompasses various facets:

A plugin should be able to invoke the microfrontend of another plugin.
Control should revert to the invoking plugin once the invoked plugin completes its tasks.
Both short-running tasks and long-running tasks should be facilitated.
For the latter, a callback mechanism is proposed, wherein the invoking plugin can be notified upon the completion of a long-running task by the invoked plugin.

The need for such interactivity stems from the inherent nature of optimization.
The \glspl{of} and minimization must closely interact to produce meaningful optimization results.
Moreover, since an invoking plugin is unaware of the parameters or requirements of the invoked plugin, direct interaction becomes imperative for dynamic data exchange and collaborative processing.

Drawing inspiration from existing systems, the interaction between the minimization and objective functions in implementations like Scipy's \emph{optimizer.minimize} \cite{2020SciPy-NMeth} function serves as a precedent.

To elevate the degree of interactivity between plugins within QHana, this thesis introduces the innovative concept of \emph{interaction endpoints}.
While QHana already employs a metadata field for plugins known as \emph{entry points} - endpoints invoked by the QHana UI to render the UI of a plugin - interaction endpoints extend this paradigm by marking specific endpoints as callable by other plugins.

A defining characteristic of an interaction endpoint is its \emph{type}.
Interaction endpoints sharing the same type uphold uniformity in their signature and return type.
This ensures that they are invoked consistently by other plugins, irrespective of their specific implementation

\subsection{Integration and Alignment with QHana}
The proposed approach complements QHana's existing principles, resonating with its emphasis on extensibility, adaptability, and user-centricity.
By enhancing the interactivity and modularity of plugins within QHana, we strive to elevate its capabilities, making it a more dynamic platform for optimization and \glspl{vqa}.

\section{Architectural Design}


\section{Implementation Strategy}
\label{sec:implementationStrategy}

\subsection{Preliminary Analysis and Design}
Before diving into the implementation, an in-depth study of the QHana documentation and a related paper on QHana's architecture \cite{Buehler2022} was undertaken to gain a comprehensive understanding of the system.
To visualize the intricate interactions and roles of various components, component diagrams were created.
Additionally, sequence diagrams were formulated to map out the sequence of interactions between plugins.

\subsection{Development Environment and Toolset}

\begin{itemize}
    \item \textbf{Visual Studio Code}: A versatile integrated development environment employed for its adaptability and support for Python development, facilitating comprehensive coding, debugging, and testing for the project.

    \item \textbf{Docker}: Utilized to run all components of QHana, ensuring consistent behavior across different computing environments.

    \item \textbf{Postman}: An API testing tool that was employed to validate and debug various endpoints, ensuring consistent and expected behavior of the plugin interactions.

    \item \textbf{Python}: As QHana is implemented in Python, it was the primary language for backend development, offering versatility and a vast library ecosystem.

    \item \textbf{HTML}: Used for creating the microfrontends, forming the user interfaces of the plugins.

    \item \textbf{Flask}: A lightweight Python web framework employed to develop the web services and RESTful APIs for the plugins.

    \item \textbf{Marshmallow}: A Python library pivotal for object serialization/deserialization, ensuring structured data transfer between the plugins.

    \item \textbf{Flask-Smorest}: An extension of Flask, offering tools for building RESTful APIs with Flask and Marshmallow, ensuring structured and accurate data transfer between plugins.

    \item \textbf{Celery}: Integrated to manage long-running tasks, particularly for objective function plugins, allowing for asynchronous task execution.

    \item \textbf{Requests}: A Python library fundamental for facilitating interactions between plugins via HTTP requests.
\end{itemize}

\subsection{Key Principles of QHana Plugins}

In the QHana ecosystem, plugins play a pivotal role in extending functionality.
The creation and integration of these plugins are governed by a set of principles that ensure their seamless operation and interaction.
For the context of this thesis, the following principles are deemed most significant:

\begin{itemize}
    \item \textbf{Plugin Definition:}
    A QHAna plugin is essentially a Python module or package. It contains a class that inherits from \texttt{QHAnaPluginBase} and should be situated in a directory specified by the \texttt{PLUGIN\_FOLDERS} configuration variable.
    The plugin runner imports all plugins from these directories, handling only the root module of the plugin.
    The plugin, in turn, is responsible for importing its implementation class and all associated Celery tasks.

    \item \textbf{Plugin Metadata and Endpoints:}
    Plugins should contain metadata and links to all their endpoints, typically located in the `./` directory.
    The metadata includes crucial information like entry points.

    \item \textbf{UI Interaction:}
    Plugins define both \texttt{href} and \texttt{hrefUi} to point to their micro frontend.
    The `hrefUi` serves the microfrontend where users input data, and `href` processes this input.

    \item \textbf{Data Handling in Multi-step Plugins:}
    For plugins that necessitate multiple user input steps, data is stored in a key-value store with dictionary-like functionality.
    Data specific to a plugin task is associated with a unique database ID, and subsequent endpoint URLs of a plugin with this ID follow the pattern \texttt{http(s)://…/<UUID>/endpointName}.

    \item \textbf{Handling Long Running Tasks:}
    Long-running tasks utilize Celery. Task names, incorporating the plugin name, must be unique.

    \item \textbf{File Loading from URLs:}
    Plugins are designed to load files from URLs.

    \item \textbf{Data Format Specification:}
    Data formats, especially those shared across plugins, should be defined as per QHAna's guidelines. For instance, for the \texttt{text/csv} format pertaining to entities:
    \begin{itemize}
        \item The first column must be the ID column (named ID). Subsequent columns represent entity attributes.
        \item The CSV file should contain a header row specifying all attribute names.
    \end{itemize}
\end{itemize}

It's imperative to note that while the outlined principles are crucial for this thesis, QHana's overarching documentation provides a more exhaustive list of best practices and guidelines for plugin creation.



\subsection{Data Handling and Transfer}
Flask-Smorest was instrumental in ensuring structured and accurate data transfer between plugins.
It aided in validating the correctness of passed data, returning appropriate error codes, and managing errors efficiently.
This ensured that data exchanges between plugins, especially in the context of \glspl{vqa}, were smooth and error-free.

\subsection{Testing and Debugging}

The quality and reliability of plugins and their interactions are paramount.
For this reason, a multi-faceted testing strategy was adopted:

\begin{enumerate}
    \item \textbf{Static Code Analysis}:
    \begin{itemize}
        \item \textbf{Purpose}: To ensure code quality, maintainability, and to identify potential vulnerabilities or deviations from coding standards.
        \item \textbf{Tools \& Implementation}: The tool \texttt{flake8} was utilized to conduct static code analysis on the Python codebase.
        By running \texttt{flake8}, a report detailing any code inconsistencies, potential errors, or areas for improvement was generated, providing valuable feedback for refinement.
    \end{itemize}

    \item \textbf{Logging and Monitoring}:
    \begin{itemize}
        \item \textbf{Purpose}: To capture, store, and analyze real-time information about the system's operations, thereby aiding in troubleshooting and understanding system behavior.
        \item \textbf{Tools \& Implementation}: Python's in-built \texttt{logging} package was leveraged to track and record various events during the execution of plugins.
        By strategically placing logging statements within the code, it was possible to gain insights into the flow of operations, detect anomalies, and pinpoint areas that might require attention.
    \end{itemize}

    \item \textbf{Interactive Debugging}:
    \begin{itemize}
        \item \textbf{Purpose}: To step through the code in real-time, inspect variables, and analyze the program's flow to identify and rectify issues.
        \item \textbf{Tools \& Implementation}: The integrated Python debugger in Visual Studio Code was employed.
        This debugger allowed for setting breakpoints, stepping through code, inspecting variable states, and examining the call stack, providing a granular view of the system's operations and aiding in issue identification and resolution.
    \end{itemize}

    \item \textbf{Manual Testing}:
    \begin{itemize}
        \item \textbf{Purpose}: To capture nuances and potential issues that might be overlooked.
        \item \textbf{Procedure}: A hands-on approach was adopted where the plugins were interactively used.
        This involved navigating through the \gls{ui}, experimenting with different inputs, and observing the system's reactions to ensure it behaved as expected and met user requirements.
    \end{itemize}
\end{enumerate}

By employing a combination of static code analysis, detailed logging, interactive debugging, and manual testing, it was ensured that the plugins were not only functionally correct but also adhered to coding standards and best practices, guaranteeing a robust and user-friendly experience.


\subsection{Performance Optimization}
For optimal performance in the microservice-based plugin architecture, several strategies were employed:

\begin{enumerate}
    \item Reducing the number of interactions between plugins.
    \item For each interaction, the amount of data transmitted across the network should be kept to a minimum to ensure efficient communication and faster response times.
    \item For tasks that require extended processing, the Celery framework should be utilized, allowing these tasks to operate asynchronously and thereby optimizing resource usage.
\end{enumerate}

These strategies were critical in ensuring swift and seamless interactions between plugins.


\subsection{Documentation and Extensibility}
To foster an environment of growth and encourage future development, comprehensive documentation detailing the process of adding new \gls{of} and minimization plugins was created.
This documentation serves as a guideline for developers aiming to extend the capabilities of QHana with interactive plugins.




\chapter{Implementation}
\label{chap:implementation}

\section{Splitting an Optimization Problem into Plugins}
\label{sec:splittingVQAsIntoPlugins}

The cornerstone of this research endeavor revolves around the modularization of \glspl{vqa} into interchangeable plugins.
This section delineates the approach and rationale for such a decomposition.

\glspl{vqa}, as previously expounded in the background section, are intrinsically optimization problems.
Fundamentally, optimization problems encompass two key components: an \gls{of}, which quantifies the problem, and a minimization function, which endeavors to find the optimal solution.
Given this inherent structure, the decision to modularize a \gls{vqa} into separate plugins for the \gls{of} and the minimization function becomes intuitive.

\subsection{Objective Function Plugin}
The \gls{of} plugin serves these pivotal roles:

\begin{itemize}
\item \textbf{Parameter Acquisition:} It presents a \gls{ui} to collect hyperparameters pertinent to the \gls{of} from the end user.
\item \textbf{Loss Computation:} Given the user-defined hyperparameters and the provided data, the plugin computes the loss function.
\item \textbf{Loss Return:} Subsequently, it returns the computed loss, which serves as an input for the minimization function plugin.
\end{itemize}

\subsection{Minimization Function Plugin}
The minimization function plugin, complementing the \gls{of}, has these essential responsibilities:

\begin{itemize}
\item \textbf{Parameter Acquisition:} Similar to its objective counterpart, this plugin offers a \gls{ui} to gather hyperparameters, but specific to the minimization function.
\item \textbf{Function Minimization:} Given the hyperparameters and the defined \gls{of} this plugin minimizes the \gls{of}.
\item \textbf{Result Return:} Upon completion, it relays the optimization result back to the coordinating entity.
\end{itemize}

\subsection{Coordinator Plugin}
To ensure the harmonious orchestration of the aforementioned plugins and to facilitate a cohesive user experience, a coordinator plugin is indispensable. Its quintessential roles are:

\begin{itemize}
\item \textbf{Data Acquisition:} Initially, it obtains the requisite data from the user.
\item \textbf{Plugin Selection:} It allows users to specify their choice of \gls{of} and minimization function plugins.
\item \textbf{UI Invocation:} Sequentially, it triggers the UIs of both the objective and minimization function plugins for hyperparameter acquisition.
\item \textbf{Optimization Execution:} With all requisite information collated, it commands the minimization function plugin to embark on the optimization of the \gls{of}.
\item \textbf{Result Presentation:} Finally, it shows the optimization result to the user, completing the cycle.
\end{itemize}

The ensuing sections will delve into the technical intricacies of achieving this modular integration within QHana.

\section{Directory Structure and Plugin Loading}
\label{sec:directoryStructure}

QHana maintains two primary directories for plugin management: the \textit{plugins} and the \textit{stable plugins} directories.
The former hosts plugins undergoing development, while the latter contains plugins that are deployment-ready.
Within these directories, individual plugins are neatly organized into dedicated subfolders.
Upon initiation, QHana scans and loads plugins from these designated subfolders.

The focus of this thesis, the optimization plugin, resides in the \textit{plugins/optimization} directory.
To promote clarity and a structured layout, further divisions were made:

\begin{itemize}
  \item \textit{plugins/optimization/coordinator} – For the main optimization plugin.
  \item \textit{plugins/optimization/objective\_functions} – Where each \gls{of} plugin occupies its respective subfolder.
  \item \textit{plugins/optimization/minimizer} – Where each minimizer plugin occupies its respective subfolder.
\end{itemize}

Given that QHana's native architecture doesn't support the direct loading of plugins from nested subdirectories, a recursive plugin loader was developed for this purpose.
This loader traverses through the \textit{plugins} directory and its subdirectories.
The presence of an \textit{\_\_init\_\_.py} file within a folder acts as a confirmation for the plugin's legitimacy.
If any plugin needs to be excluded from the loading process, a \textit{.ignore} file is placed in its respective folder to act as a loading deterrent.

To ensure that the recursive process doesn’t compromise system performance, the recursion depth is capped at 4.
This threshold sufficiently accommodates the current plugin structure but can be adjusted upwards if future needs arise.

The folder hierarchy is further enriched by the inclusion of an \textit{interaction\_utils} directory, dedicated to housing utility functions for generalized plugin interactions.
Additionally, there's a \textit{shared} directory, which stores data structures and schemas utilized across the plugins related to optimization plugin.
A visual representation of the final folder structure, with all plugins implemented for this thesis, is shown in \cref{fig:folderStructure}.


\begin{figure}[h!]
  \dirtree{%
      .1 plugins.
      .2 optimizer.
      .3 coordinator.
      .3 interaction\_utils.
      .3 minimizer.
      .4 scipy\_minimizer.
      .4 scipy\_minimizer\_grad.
      .3 objective\_functions.
      .4 hinge\_loss.
      .4 neural\_network.
      .4 ridge\_loss.
      .3 shared.
  }
  \caption{QHana Plugin Folder Structure.}
  \label{fig:folderStructure}
\end{figure}


\section{Interaction Endpoints}
\label{sec:interactionEndpoints}
this thesis introduces the concept of interaction endpoints to qhana
qhana already defines a metadata field for pluings called entry points which are edndpoints called by the qhana ui to render the ui of a plugin
interaction endpoints add to this conecpt by defining endpoints that are callable by other plugins
an interaction endoint has a type.
all interaction endpoints which the same type must have the same signature and return type and can be called in the same way by other plugins
in the case of of objective function plugins for example one interaction endpoint type is the \emph{objectivefunctioncalc} type which is used to calculate the loss function
all plugins that have this type of interaction endpoint can be used as an objective function plugin

this concept has several advantages
* it allows for full interchangeability of plugins
* it allows the developer that want to interact with a plugin to know what endpoints are available and how to call them
* an alternatiev would be to return the url of available endpoitns after passing through the ui, now we can completely skip the ui alltogether and just call the endpoint directly


\section{Plugin interaction}
\label{sec:pluginInteraction}

coordinator plugin gets the metadata of the metadata of the of and min plugin via a simple get request to the metadata endpoint of the plugins
the metadata contains the entry point to the plugins which is the user interface and the ineteraction endpoints which are other endpoints of a plugin that can be called by other plugins
the coornator then calls the entry point of the of plugin and passes along a callback url to which the of plugin should make a post request when it is done with its setup
after the user has entered the hyperparameters for the of plugin the user clicks submit and the of pluings saved the hyperparameters to the database and makes a post request to the callback url
the callback url is the processing endpoint of the coordinator plugin
the coordinator plugin then calls the entry point of the min plugin and passes along the callback url to which the min plugin should make a post request when it is done with its setup
after the user has entered the hyperparameters for the min plugin the user clicks submit and the min pluings saved the hyperparameters to the database and makes a post request to the callback url
the callback url is the processing endpoint of the coordinator plugin


\section{Implementation of an Objective Function Plugin}
\label{sec:implementationOfAnObjectiveFunctionPlugin}

to go over the taks of an of plugin again:
* parameter acquisition
* loss computation
* loss return

\subsection{Parameter Acquisition}
\label{subsec:parameterAcquisition}
parameter acquisition is done via an ui that is rendered by the plugin.
the ui is no new concept but follows the standard concept of an microfrontend in qhana
it presents the user with a form that is defined in a marshmallow schema
that schema holds the hyperparameters of the of plugin
in case of a ridge loss plugin this hyperparameter is the alpha value as described in the background section
when clicking submit the ui makes a post request to the processing endpoint of the plugin
this processing endpoint saves the hyperparameters to the database and makes a post

to allow for interaction between plugins the ui has some additional functionality
since it is a invocable plugin a callback url to and invoking plugin endpoint is passed to the ui via a query parameter
it is a query parameter since the has to be called with an get request and get requests can only have query parameters
the ui endpoint forwards the callback url to the processing endpoint of the of plugin as a query parameter
the processing endpoint then makes a post request to the callback url when it is done with its setup

\subsection{Objective Function interaction endpoints}
\label{subsec:objectiveFunctionInteractionEndpoints}
the of plugin should provide several interaction endpoints
on is the pass data endpoint
this endpoint is called to pass input data to the of plugin
there are several reasons why this is done via an interaction endpoint and not via ui input
* the data is not specific to the of plugin but is shared between the of plugin and the min plugin, so therefore the user should not have to enter it here but rather in the coordinator plugin
* one could think that the cooridnator plugin could just pass the data to the of plugin via the ui endpoint, but this would mean passing huge ammonts of data via a get request which is not a good idea
* one could think about passing a link to a file that contains the data, but this would mean that the of plugin would have to download the file and parse it, this should not be the job of the of plugin
* the minimization plugin could pass the data to the of plugin when calling the of plugin to calculate the loss, but this would mean that one the min pluing needs to know the data, which otherwise is not necessary, 2. the min plugin would have to pass the data to the of plugin every time it calls the of plugin to calculate the loss, which would cause a lot of network traffic, 3. it would make the process less generic, since the min plugin would have to know how to pass the data to the of plugin

this endpoint can simply be called by a invoking plugin via a post request and returns directly after saving the data to the database
this endpoint also returns the metadata numberofweights which is the number of weights that the of plugin needs to calculate the loss function
this is needed by a minimization plugin to know how many weights it needs to pass to the of plugin when calling the of plugin to calculate the loss function
the number of weights is passed here since it is can depend on the data and the of hyperparameters and therefore is not known when the metadata is requested

one interaction endpoint is the loss fucntion calculation endpoint
this endpoint is called to calculate the loss function
it can be called by a invoking plugin via a post request
the arugments passed to the endpoints are the weights of the model
the endpoint then calculates the loss function and returns it

an optinal interaction endpoint is the gradient calculation endpoint
this endpoint is called to calculate the gradient of the loss function
it can be called by a invoking plugin via a post request
the arugments passed to the endpoints are the weights of the model
the endpoint then calculates the gradient of the loss function and returns it

another optional interaction endpoitn is the gradient and loss function calculation endpoint
this endpoint combined the two previous endpoints into one since the loss function and the gradient of the loss function are often calculated together and so makes the process more efficient
it can be called by a invoking plugin via a post request
the arugments passed to the endpoints are the weights of the model
the endpoint then calculates the loss function and the gradient of the loss function and returns them


\section{Implementation of a Minimization Function Plugin}
\label{sec:implementationOfAMinimizationFunctionPlugin}
to go over the taks of an min plugin again:
* parameter acquisition
* function minimization
* result return

\subsection{Parameter Acquisition}
\label{subsec:parameterAcquisition}
parameter acquisition is done the same way as for the of plugin
as an example for the min plugin that uses the scipy minimize function the hyperparameter is the method that is used to minimize the function

\subsection{Minimization Function interaction endpoints}
\label{subsec:minimizationFunctionInteractionEndpoints}

a minimization plugin provides a single interaction endpoint
this endpoint is called to minimize the of
the arugments passed to the endpoints is the url of the of plugin loss calculation endpoint, the weights of the model, and a callback url to the invoking plugin
some optinal arguments can be the url of the of plugin gradient calculation endpoint and the url of the of plugin gradient and loss function calculation endpoint
these optional arguments are only considrered if the minimization plugin implements a minimization function that uses the gradient of the loss function
the endpoint schedules an asyncronous celery task that minimizes the of
it return directly after scheduling the task

the celery task minimizes the of by calling the calcucation endpoint over and over again
a novel approach is used to make a callback to the invoking plugin
qhana provides a way url to an celery task of a plugin that can be called to get the status of the task
this status is stored in a database
the python library blinker is used to to track changes to the status of the task
now when the status of a task changes the blinker library calls a function that is registered to the status change event
this function then makes a post request to the callback url of the invoking plugin
this way the invoking plugin is notified when the task is done and does not have to poll the status of the task

\section{Implementation of a Coordinator Plugin}

\section{Plugin Infrastructure}
\label{sec:pluginInfrastructure}
\section{Plugin Interaction}
\label{sec:pluginInteraction}
\section{Minimizer Plugin}
\label{sec:minimizerPlugin}
\section{Objective Function Plugins}
\label{sec:objectiveFunctionPlugins}


\chapter{Evaluation}
\label{chap:evaluation}
\section{Sample Machine Learning Experiment}
\label{sec:sampleMachineLearningExperiment}
\section{Interchangeability of Plugins}
\label{sec:interchangeabilityOfPlugins}
\section{Performance Analysis}
\label{sec:performanceAnalysis}

The performance of the system is evaluated by measuring the time the system takes to complete a machine learning experiment.
The time that it takes for a user to input the data is not measured.
This benchmark should only measure the time that it takes for the system to complete the experiment.
We compare the performance of the plugin based system with the performance of a jupyter notebook based system.
There are several steps that are benchmarked in the plugin based system, since there is user interaction between the steps.
\begin{itemize}
  \item The time that it takes after the user has selected the plugins until the user can input the hyperparameters for the of plugin.
  \item The time that it takes after the user has input the of plugin hyperparameters until the user can input the hyperparameters for the minimizer plugin.
  \item The time that it takes after the user has input the minimizer plugin hyperparameters until the user gets the result of the experiment.
\end{itemize}
The times of those steps are summed up to get the total time that it takes for the plugin based system to complete the experiment.
The time that it takes for the jupyter notebook based system is measured from the start of the notebook until the user gets the result of the experiment.
The time is measured by adding a timestamp at the start of the step and at the end of the step.
The difference between the two timestamps is the time that it takes for the step to complete.
The time that it takes for the plugin based system to complete the experiment is compared to the time that it takes for the jupyter notebook based system to complete the experiment.
In order to get a more accurate result, the experiment is repeated several times and the average time is taken.
To make it as comparable as possible, the same datasets and hyperparameters are used for both systems.
The output file of the experiment should also have the same exact format.

Since the benchmark of the plugin based system shows worse performance than the jupyter notebook based system, we want to explore where the most time is spent.
Therefore, we measure the time it takes to call to calculate the loss function.
In case of the plugin based system this includes the network latency between the plugins.
We want to see how much time is spent in the network and how much time is spent in the actual calculation of the loss function.

For more sophisticated loss functions (in this case the neural network) we want to see how much time is spent for the setup of the neural network.
Since a microservice does not have state, the neural network has to be setup for every call of to calculate loss function.

\section{Hardware and System Specifications}

The benchmarks were conducted on a MacBook Pro. The detailed specifications of the machine are as follows:

\begin{itemize}
    \item \textbf{Model:} MacBookPro18,1
    \item \textbf{Processor (CPU):} Apple M1 Pro
    \item \textbf{Memory (RAM):} 32 GB (hw.memsize: 34359738368 bytes)
    \item \textbf{Graphics Processing Unit (GPU):}
    \begin{itemize}
        \item Chipset Model: Apple M1 Pro
        \item Type: GPU
        \item Bus: Built-In
        \item Total Number of Cores: 16
        \item Metal Support: Metal 3
    \end{itemize}
    \item \textbf{Operating System:} macOS, Version 13.4.1, Build Version: 22F770820d
\end{itemize}


\section{Accuracy Analysis}
\label{sec:accuracyAnalysis}
In terms of accuracy we compare the results of the plugin based system with the results of the jupyter notebook based system.
The results of the two systems should be the same, since the same datasets and hyperparameters are used.
Also, we should see the same results since the same actual code is executed in both systems, only the way of calling the code is different.
The results are compared by calculating the mean squared error between the two results.



\chapter{Discussion}
\label{chap:discussion}
\section{Achievements and Contribution}
\label{sec:achievementsAndContribution}
\section{Limitations}
\label{sec:limitations}


\chapter{Conclusion and Outlook}
\label{chap:zusfas}

\section{Outlook}

\printbibliography

All links were last followed on October 15, 2023.

\appendix

\pagestyle{empty}
\renewcommand*{\chapterpagestyle}{empty}
\Versicherung
\end{document}
