% !TeX spellcheck = en-US
% !TeX encoding = utf8
% !TeX program = pdflatex
% !BIB program = biber
% -*- coding:utf-8 mod:LaTeX -*-
% !TEX root = ./main-english.tex

% vv  scroll down to line 200 for content  vv


\let\ifdeutsch\iffalse
\let\ifenglisch\iftrue
\input{pre-documentclass}
\documentclass[
  % fontsize=11pt is the standard
  a4paper,  % Standard format - only KOMAScript uses paper=a4 - https://tex.stackexchange.com/a/61044/9075
  twoside,  % we are optimizing for both screen and two-side printing. So the page numbers will jump, but the content is configured to stay in the middle (by using the geometry package)
  bibliography=totoc,
  %               idxtotoc,   %Index ins Inhaltsverzeichnis
  %               liststotoc, %List of X ins Inhaltsverzeichnis, mit liststotocnumbered werden die Abbildungsverzeichnisse nummeriert
  headsepline,
  cleardoublepage=empty,
  parskip=half,
  %               draft    % um zu sehen, wo noch nachgebessert werden muss - wichtig, da Bindungskorrektur mit drin
  draft=false
]{scrbook}
\input{config}


\usepackage[
  title={Implementing Variational Quantum Algorithms as Compositions of Reusable Microservice-based Plugins},
  author={Matthias Weilinger},
  type=master,
  institute=iaas, % or other institute names - or just a plain string using {Demo\\Demo...}
  course={Informatik},
  examiner={Prof.\ Dr.\ Dr.\ h.\ c.\ Frank Leymann},
  supervisor={M.Sc.\ Philipp Wundrack,\\M.Sc.\ Fabian Bühler},
  startdate={April 19, 2023},
  enddate={October 19, 2023}
]{scientific-thesis-cover}

\input{acronyms}

\makeindex

\begin{document}

%tex4ht-Konvertierung verschönern
\iftex4ht
  % tell tex4ht to create picures also for formulas starting with '$'
  % WARNING: a tex4ht run now takes forever!
  \Configure{$}{\PicMath}{\EndPicMath}{}
  %$ % <- syntax highlighting fix for emacs
  \Css{body {text-align:justify;}}

  %conversion of .pdf to .png
  \Configure{graphics*}
  {pdf}
  {\Needs{"convert \csname Gin@base\endcsname.pdf
      \csname Gin@base\endcsname.png"}%
    \Picture[pict]{\csname Gin@base\endcsname.png}%
  }
\fi

%\VerbatimFootnotes %verbatim text in Fußnoten erlauben. Geht normalerweise nicht.

\input{commands}
\pagenumbering{arabic}
\Titelblatt

%Eigener Seitenstil fuer die Kurzfassung und das Inhaltsverzeichnis
\deftriplepagestyle{preamble}{}{}{}{}{}{\pagemark}
%Doku zu deftriplepagestyle: scrguide.pdf
\pagestyle{preamble}
\renewcommand*{\chapterpagestyle}{preamble}



%Kurzfassung / abstract
%auch im Stil vom Inhaltsverzeichnis
\ifdeutsch
  \section*{Kurzfassung}
\else
  \section*{Abstract}
\fi

<Short summary of the thesis>

\cleardoublepage


% BEGIN: Verzeichnisse

\iftex4ht
\else
  \microtypesetup{protrusion=false}
\fi

%%%
% Literaturverzeichnis ins TOC mit aufnehmen, aber nur wenn nichts anderes mehr hilft!
% \addcontentsline{toc}{chapter}{Literaturverzeichnis}
%
% oder zB
%\addcontentsline{toc}{section}{Abkürzungsverzeichnis}
%
%%%

%Produce table of contents
%
%In case you have trouble with headings reaching into the page numbers, enable the following three lines.
%Hint by http://golatex.de/inhaltsverzeichnis-schreibt-ueber-rand-t3106.html
%
%\makeatletter
%\renewcommand{\@pnumwidth}{2em}
%\makeatother
%
\tableofcontents

% Bei einem ungünstigen Seitenumbruch im Inhaltsverzeichnis, kann dieser mit
% \addtocontents{toc}{\protect\newpage}
% an der passenden Stelle im Fließtext erzwungen werden.

\listoffigures
\listoftables

%Wird nur bei Verwendung von der lstlisting-Umgebung mit dem "caption"-Parameter benoetigt
%\lstlistoflistings
%ansonsten:
\ifdeutsch
  \listof{Listing}{Verzeichnis der Listings}
\else
  \listof{Listing}{List of Listings}
\fi

%mittels \newfloat wurde die Algorithmus-Gleitumgebung definiert.
%Mit folgendem Befehl werden alle floats dieses Typs ausgegeben
\ifdeutsch
  \listof{Algorithmus}{Verzeichnis der Algorithmen}
\else
  \listof{Algorithmus}{List of Algorithms}
\fi
%\listofalgorithms %Ist nur für Algorithmen, die mittels \begin{algorithm} umschlossen werden, nötig

% Abkürzungsverzeichnis
\printnoidxglossaries

\iftex4ht
\else
  %Optischen Randausgleich und Grauwertkorrektur wieder aktivieren
  \microtypesetup{protrusion=true}
\fi

% END: Verzeichnisse


% Headline and footline
\renewcommand*{\chapterpagestyle}{scrplain}
\pagestyle{scrheadings}
\pagestyle{scrheadings}
\ihead[]{}
\chead[]{}
\ohead[]{\headmark}
\cfoot[]{}
\ofoot[\usekomafont{pagenumber}\thepage]{\usekomafont{pagenumber}\thepage}
\ifoot[]{}


%% vv  scroll down for content  vv %%































%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Main content starts here
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Notes what I have done so far}
\begin{itemize}
  \item Added recursive parsing of the plugin folders so that subfolders are also parsed
  \item created a callable plugin that gets the data parsed from its invoker via the database
  \item created a invoker that calls the callable plugin
  \item user can now select a plugin from the list of callable plugins, the list is narrowed down to the plugins that are compatible via the tag field
  \item creating a method to get the plugin name from the plugin URL
  \item made the callee plugin to multistep, to demonstrate that any amount of steps can be done in invoked plugin
  \item started with an optimizer plugin that gives the first frontend for the user to select the objective-function-plugin
  \item create an objective-function-plugin that takes means squared error as an objective function
  \item todo: creating a method to get the plugin metadata from the plugin URL (this is needed in order to get the entry points of the plugin)
  \item identified three key problems:
  \begin{itemize}
    \item Reliable way to pass a callback function to the callee plugin
    \item A way to get a list of interaction endpoints of the callee plugin
    \item A way to get the plugin metadata from the plugin URL
  \end{itemize}
  \item 19.05: I am currently working on a big problem
  \begin{itemize}
    \item I have the optimizer plugin which should call the objective-function-plugin so that it can ask the user for the hyperparameters of the objective function
    \item For that reason I need to add a next step as a celery task.
    \item The thing is i don't want to handle the next task like other multistep plugins where they share a db id since the objective-function-plugin should be able to stand on its own.
    \item Therefore, I pass a callback function to the objective-function-plugin which it should call when it is done with the setup.
    \item works all fine like that
    \item The problem right now is how i call the objective-function-plugin from the optimizer plugin
    \item I need to add it as a step, which is usually done via the add\_step celery task
    \item This task though needs a db\_id which I don't want to add.
    \item When adding none it works to call the objective-function-plugin and its also possbile to call the callback function
    \item but the problem is that with the add\_step task the celery task is not called asyncronously
    \item therefore when the callback function is called the optimizer plugin is not yet finished with the add\_step task
    \item usually one would go in the called multistep and do a clear\_previous\_steps call to make sure that the previous steps are finished
    \item but this call does not work since the objective-function-plugin does not have a db\_id
    \item thinking right now....
    \item maybe we can finish the task in the callback function of the optimizer plugin?
    \item Still 19.05 here we are again
    \item I have now a working solution for the problem
    \item the proposed solution of clearing the previous steps in the callback function did work
    \item the problem was that i forgot to add the call db\_task.save(cammit=True) in the callback function
    \item this is needed to save the changes to the database without it the cleared variable is not saved
  \end{itemize}
  \item 20.05: Today we give the objective-function-plugin the ability to calculate the loss function
  \begin{itemize}
    \item On callback we give the optimizer plugin the url of the calculateLoss function url
    \item The optimizer plugin then calls the calculateLoss function
  \end{itemize}
  \item 22.05: we continue with the upper
  \begin{itemize}
    \item it is now possible to calculate the loss function
    \item we simply call the calculation enpoint with a post request
    \item we pass all the necessary data in the body of the request
    \item we have a special schema for that
    \item current problem: passing the data to the minimize function of scipy.optimize
    \item we have the hyperparameters as a dict to keep it as generic as possible
    \item but the minimize function needs the hyperparameters as a list
    \item and also the loss function needs the hyperparameters as a dict, so lets see how we can solve this
    \item we maybe did it by just passing the hyperparameters as a dict to both of the functions
    \item now we have the problem that the content type of the input file is not correctly set by postman
    \item we just change the code to accept the content type but lets not forget to change it back
  \end{itemize}
  \item 23.05: today we do some cleanup
  \begin{itemize}
    \item make the import relative so that it works with the docker container
    \item remove all no ops tasks
  \end{itemize}
  \item 02.06:
  \begin{itemize}
    \item we want to skip the optimizer UI since we do not need any more input data
    \item tried to set the cleared value of the created step to true, but it did not work, since only the process step is started is by clicking submit in the ui
    \item trying to chain the tasks directly in the callback function, which works
  \end{itemize}
  \item 05.06:
  \begin{itemize}
    \item now I want to call the objective-function-plugin via the entry points that I get through the metadata, this is needed to make the plugins more generic
    \item I have a problem where the shared schemas can not be imported since the NumPy package cannot be found, added the NumPy package to the requirements for the opt plugin, but this did not solve the problems
    \item maybe this will be solved by creating a coordinator plugin that lives in the top level of the plugin folder
  \end{itemize}
  \item 12.06:
  \begin{itemize}
    \item Creating a top level coordinator plugin was not the solution. If an init file is present no further plugins will be loaded from the folder
    \item the shared schemas are now part of the coordinator plugin
    \item Created a new infrastructure for the plugins with a coordinator plugin (diagram will be needed)
    \item today we solve the following problem:
    \item coordinator waits for the optimizer plugin to finish and writes the result to a file
    \item for this the coordinator polls the task api to check if the minimizer task is finished
    \item when it is it writes the result to a file
    \item I should move the callback URL away from the query parameters to the body of the request, maybe to the form
    \item next I should read about how neural networks work and how to minimize them
  \end{itemize}
  \item 13.06:
  \begin{itemize}
    \item i have made a decision on how to handle the callback url from the ui to the processing endpoint
    \item until now the callback url was passed as a query parameter
    \item now i want to pass it into the form that is rendered by the UI
    \item it should be a hidden field
    \item i have to make and change so that i can pass multiple schemas to the render function and set which fields should be hidden
  \end{itemize}
  \item 16.06:
  \begin{itemize}
    \item when an invoked plugin now makes a callback to its invoker it only passes back the endpoint for the calculation endpoint.
    \item it does not pass any hyperparameters back since it should own the hyperparameters and not the invoker
    \item i now want to have a look of how loss functions are called in python and how hyperparameters are passed to them
    \item with this information I want to create interaction endpoints for the objective-function-plugin that are completely generic, i.e. the hyperparameters are passed to the endpoint as a dict
    \item as an example of how a generic method could look like i will have a look at the scipy.optimize.minimize function
    \item I now interaction endpoints as and additional list to entry points
  \end{itemize}
  \item 25.06:
  \begin{itemize}
    \item i have added a functionality where I use the blinker library to create a signal that is emitted when the status of a task changes
    \item this is used by the coordinator plugin to check if the minimization task is finished
    \item the coordinator plugin passes the callback URL to the minimization calculation endpoint
    \item this endpoint registers the URL to the db
    \item the signal handlers makes a post request to this URL when the status of the task changes
    \item I have moved all shared schemas into a separate folder
    \item I have moved all utilities concerning plugin interactions into a separate folder
  \end{itemize}
  \item 26.06:
  \begin{itemize}
    \item I developed a way to pass any amount of parameters to the processing endpoint of the invoked plugin UI
    \item I added an interaction endpoint that is used to invoke the invoked plugin
    \item this interaction endpoint allows any number of parameters
    \item the endpoint saves these parameters to the database
    \item it then adds the entry points of the invoked plugin as a step
    \item it passes the processing URL with the db id as a query parameter to the invoked plugin
    \item the invoked plugin then calls the processing endpoint with the db id as a query parameter
    \item here it starts a new db task with the arguments that were passed to the invoked plugin
  \end{itemize}
\end{itemize}


\chapter{Define the plugins}
\begin{itemize}
  \item \textbf{ObjectiveFunction}: This plugin should have the following steps
  \begin{itemize}
    \item \textbf{ /get hyperparameterUI }: This step should let the user select the hyperparameters of the objective function
    \item \textbf{ /post ObjectiveFunctionSetup}: This step should setup the objective function with set a database id for future reference of the parameter.
    Then it should store the following information to the database:
    \begin{itemize}
      \item hyperparameters
      \item more stuff?? %%% TODO specify what more stuff
    \end{itemize}
    Then it should call the optimizer callback function to indicate that the setup is done. Pass the url of the calculateLoss function as a parameter.
    \item \textbf{ /post CalculateLoss (dbID) }: this step should trigger the calculation of the loss function and should return it.
  \end{itemize}
  \item \textbf{Optimizer}: This plugin should have the following steps:
    \begin{itemize}
      \item \textbf{ /get setup UI }: Let the user select the objective-function-plugin, dataset, target variable, and the optimization algorithm
      \item \textbf{ /post setup }: This step should setup the optimizer with set a database id for future reference of the parameter.
      Then it should call the objective function entry point to setup the objective function. Pass the url of the optimizer callback function as a parameter.
      \item \textbf{ /post callback }: This endpoint should be called by the objective-function-plugin to indicate that the setup is done.
      It should then start the optimization process.
      \item \textbf{ /post optimize }: This step should trigger the optimization process.
      It should loop the optimization function until a stop condition is met.
      In each iteration it should call the objective-function-plugin to calculate the loss function.
    \end{itemize}
\end{itemize}

\chapter{Introduction}
\label{chap:introduction}

\chapter{Background}
\label{chap:background}

The study of \gls{qhana} and its advanced plugin interactions is rooted in a set of foundational principles that underpin its functionality.
This chapter aims to offer a comprehensive introduction to these principles, encompassing key areas such as optimization algorithms, quantum computing, \glspl{vqa}, \gls{rest}, and the core architecture of \gls{qhana}.
By delving into these foundational topics, readers will gain the necessary context to understand the innovative approaches adopted in this thesis.

\section{QHana}
\label{sec:qhana}

\gls{qhana} was conceived as a specialized application in the domain of Digital Humanities.
Its primary design offers users a platform to explore various machine learning algorithms on designated datasets.
While the primary vision of \gls{qhana} was to assess the potential advantages of quantum algorithms within the DH community, the rise and cloud availability of quantum computers further underscore its relevance and timeliness.

\gls{qhana} is designed to be extensible, allowing the integration of new data sources and quantum algorithms as plugins.
However, plugins are built for specific applications, limiting their reusability in other contexts.
Moreover, plugins for an application have to be developed in the same programming language as the application.
Even if a plugin can be reused in another application, its UI has to adapt to the new application, otherwise users may fail to understand the plugin's functionality.
To address this limitation, \gls{qhana} is built on a novel concept of Reusable Microservice-based Plugins (RAMPs).
This allows microservices with an integrated UI to be used as plugins by multiple applications, enhancing the reusability of the plugins across different applications \cite{Buehler2022}.

Central to this thesis is the integration of \glspl{vqa}
The envisioned approach allows for plugins to interact and collaborate, enabling the implementation of \glspl{vqa} as modular components within \gls{qhana}.

\section{Quantum Computing}
\label{sec:quantumComputing}
Quantum computing is a cutting-edge field that exploits the principles of quantum mechanics to process information.
Unlike classical computers that use bits (0s and 1s) to store and process information, quantum computers use quantum bits, or \emph{qubits}.
Qubits, through the phenomena of superposition and entanglement, can exist in multiple states at once and be correlated with each other in ways that classical bits cannot \cite{Nielsen2010}.

Superposition allows a qubit to be in a state that is a combination of both 0 and 1, with a certain probability for each.
This property enables quantum computers to perform many calculations simultaneously, vastly increasing their potential computational power.
Entanglement, on the other hand, allows qubits that are entangled to be intimately linked regardless of the distance separating them.
A change in the state of one will instantaneously affect the state of the other, a phenomenon that Einstein famously called spooky action at a distance \cite{Einstein1935}.
This property is essential for many quantum algorithms, quantum error correction, and quantum teleportation, making it a fundamental resource in quantum information processing \cite{Nielsen2010,Preskill1998}.


\section{Variational Quantum Algorithms}
\label{sec:variationalQuantumAlgorithms}

\glspl{vqa} bring together the principles of quantum computing and optimization in a unique and powerful way.
They are a class of hybrid quantum-classical algorithms that leverage the strengths of both quantum and classical computing to solve complex problems \cite{McClean2016}.

The main concept of \glspl{vqa} is to use a sequence of quantum operations (a "quantum circuit") controlled by certain parameters.
These parameters are adjusted using classical optimization techniques with the aim of solving a specific problem.
This problem, in many cases, involves finding the lowest energy state, or "ground state", of a quantum system, a problem that maps to finding the minimum of a particular function \cite{Peruzzo2013}.

By leveraging classical optimization algorithms, \glspl{vqa} become more resistant to quantum errors, as the majority of the computation is performed on a classical computer.
This combination of quantum and classical resources makes \glspl{vqa} a promising type of algorithm for near-term quantum devices \cite{Moll2017}.


\section{Optimization Algorithms}
\label{sec:optimizationAlgorithms}
Optimization is a powerful tool that's ubiquitous in various scientific and technological domains.
At its core, optimization is about finding the best solution from a set of possible choices.
This section provides a snapshot of optimization's fundamental principles, paving the way for its deeper exploration in the context of \glspl{vqa} and finally microservice based \glspl{vqa}.

\subsection{Objective Functions}
\label{subsec:objectiveFunctions}
\glspl{of} are fundamental to optimization problems, underpinning a myriad of computational algorithms and models.
Depending on specific requirements, the aim might be to minimize or maximize these functions.
Notably, within the realm of \glspl{vqa}, the focus is primarily on function minimization \cite{Weinan2017}.

The core inputs to a \gls{of} typically encompass data points (denoted as $x$), corresponding labels or outcomes (represented by $y$), and a set of parameters or weights (often symbolized by $\theta$ or $w$).
These parameters dictate how the model responds to the input data and makes its predictions.
Additionally, certain \glspl{of} may also include hyperparameters as input, which control the behavior and complexity of the model.
In the context of optimization problems, the role of an \gls{of} is to capture both the problem we're attempting to solve and the strategy by which we're trying to solve it.
It provides a measure of the 'goodness' or 'fitness' of our current solution or parameters, and the aim is to adjust these parameters to improve this measure.

One example of an \gls{of} is the Lasso (Least Absolute Shrinkage and Selection Operator) Loss function.
The Lasso loss function is represented as:
\[
L(Y, X, W, \lambda) = ||Y - XW||^2_2 + \lambda ||W||_1
\]
In this equation:

\begin{itemize}
  \item \(Y\) is the vector of observed values.
  \item \(X\) is the matrix of input data points.
  \item \(W\) is the vector of weights, the parameters of the model.
  \item \(\lambda\) is the regularization parameter, a non-negative hyperparameter.
\end{itemize}

This function consists of two terms:
\begin{enumerate}
  \item The first term \(||Y - XW||^2_2\) is the mean squared error between the predicted and actual outcomes.
  It measures the discrepancy between the model's predictions and the true values.
  \item The second term \(\lambda ||W||_1\) is a regularization term, where \(||W||_1\) represents the L1 norm (sum of absolute values) of the weight vector.
  This term penalizes the absolute size of the coefficients, encouraging them to be small.
\end{enumerate}
The hyperparameter \(\lambda\) governs the trade-off between these two terms.
When \(\lambda = 0\), the \gls{of} reduces to ordinary least squares regression, and the weights are chosen to minimize the mean squared error alone.
As \(\lambda\) increases, more weight is given to the regularization term, and the solution becomes more sparse (i.e., more of the weights are driven to zero).
This can help to prevent overfitting by effectively reducing the complexity of the model \cite{ShalevShwartz2014}

\subsection{Minimization Functions}
\label{subsec:minimizationFunctions}
Minimization functions, often referred to as optimization algorithms, play a pivotal role in a vast array of computational models and algorithms.
In essence, they serve to iteratively enhance the parameters of a model to reduce the value of the \gls{of}.
The goal of these minimization functions is to find the optimal set of parameters that yield the lowest possible value of the \gls{of} within the constraints of the problem \cite{Nocedal2006}.

The process of optimization involves a search through the parameter space.
This search can be visualized as navigating a landscape of hills and valleys, with each point in the landscape corresponding to a different set of parameters, and the height at each point representing the value of the \gls{of}.
The goal of the minimization function is to find the lowest point in this landscape, corresponding to the minimum value of the \gls{of} \cite{Goodfellow2017}.

The core inputs to a minimization function are the initial parameters of the model or weights (denoted as \(\theta\) or \(w\)),
the \gls{of} that needs to be minimized, and the gradients of the \gls{of} with respect to the parameters.
Additionally, certain minimization functions may also include hyperparameters as input, which control the behavior and complexity of the optimization process \cite{Virtanen2020}.
For instance, the learning rate is a typical hyperparameter that determines the step size in each iteration of the optimization process.

There are numerous minimization functions used in computational problems, each with its own strengths and weaknesses.
These range from simple methods such as gradient descent, to more complex ones such as the Newton's method, stochastic gradient descent (SGD), RMSprop, and Adam.

One of the most fundamental and widely used minimization functions is the Gradient Descent.
To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.

The update rule of gradient descent is given as:

\[
\theta_{t+1} = \theta_t - \alpha \nabla F(\theta_t)
\]

In this formula:

\begin{itemize}
  \item \(\theta_{t+1}\) represents the parameters at the next time step.
  \item \(\theta_t\) represents the current parameters.
  \item \(\alpha\) is the learning rate, a positive scalar determining the size of the step.
  \item \(\nabla F(\theta_t)\) is the gradient of the \gls{of}.
\end{itemize}

Here, the \gls{of} \(F\) is assumed to be a differentiable function.
The gradient \(\nabla F(\theta_t)\) provides the direction of the steepest ascent at the point \(\theta_t\), and \(-\nabla F(\theta_t)\) provides the direction of steepest descent.
By taking a step in this direction, we move towards the minimum of the function.

The size of the steps taken is determined by the learning rate \(\alpha\), which is a hyperparameter that must be set before the learning process begins.
The learning rate controls how fast or slow we move towards the optimal weights.
If the learning rate is very large, we may skip the optimal solution.
If it is too small, we may need too many iterations to converge to the best values.

The choice of minimization function can significantly influence the efficiency and success of the optimization process.
While some minimization functions may perform well on certain problems, they may not yield similar results on others.
Therefore, understanding the underlying mechanisms of these functions and their suitability to the specific problem at hand is crucial.


\section{RESTful API Design}
In the evolving landscape of software design, microservices have emerged as a preferred architectural style, prized for their modularity, scalability, and independent deployability.
At the heart of \gls{qhana}'s design is a microservices-based plugin approach, which facilitates its dynamic and extensible nature.
Central to the orchestration of these microservices is the application of \gls{rest}ful API design.
\gls{rest} is an architectural style that sets forth constraints for creating web services.
\gls{rest}ful APIs, built upon these constraints, are pivotal in ensuring seamless communication between individual microservices, thereby enabling efficient data exchange and service integration.

For those seeking a deeper dive into the intricacies of \gls{rest}ful design in microservices architectures, influential works by Fielding \cite{Fielding2000} and practical insights by Richardson and Amundsen \cite{Richardson2013} are recommended.

\chapter{Problem Statement and Objectives}
\label{chap:problem}

Optimization algorithms, with their ability to find the best possible solution from a set of feasible solutions, play a pivotal role in numerous computational domains.
\glspl{vqa} are a subset of these algorithms that leverage quantum computing principles, particularly in the realm of \glspl{of} and minimization techniques.
However, the true potential of optimization, and by extension \glspl{vqa}, is often hindered by rigid platforms where the components of these algorithms are tightly integrated, limiting adaptability and innovation.

\gls{qhana}, with its unique environment tailored for experimenting with a myriad of machine learning and quantum algorithms, presents an opportunity to redefine this paradigm.
Yet, its current architecture does not fully exploit the modular benefits that can be achieved by decoupling the components of optimization algorithms.
Furthermore, while developing this modular framework, it's essential to allow for plugins to interact with each other.
This interaction-centric concept, once established, can be universally applied across \gls{qhana}, not just for optimization but for any scenario where plugin interaction is required.

\textbf{Problem Statement:}
How can we design and implement a modular framework within \gls{qhana} that allows components of optimization algorithms, specifically \glspl{of} and minimization functions, to be encapsulated as distinct, interchangeable plugins?
Furthermore, how can these plugins, especially in the context of \glspl{vqa}, be structured to communicate and collaborate seamlessly?

This problem encompasses several challenges:

\begin{itemize}
    \item \textbf{Communication:} Establishing a robust communication mechanism that enables interaction, data sharing, and collaboration among these plugins.
    \item \textbf{Interchangeability:} Designing a system where different \gls{of} and minimization plugins can be effortlessly swapped, ensuring adaptability in optimization and \glspl{vqa}.
    \item \textbf{Standardization:} Implementing a consistent interface for these plugins, ensuring uniformity and compatibility across various \gls{of} and minimization plugins.
    \item \textbf{User Experience:} Providing an intuitive environment where users can easily select, interchange, and experiment with different optimization components tailored to their needs and provide developers with an extensible framework to build new minimization and \gls{of} plugins.
\end{itemize}

Addressing this problem is essential to enhance the capabilities of \gls{qhana}, transforming it into a dynamic, adaptable, and user-centric platform for optimization and VQAs.
The subsequent sections of this thesis will delve into the methodologies, implementations, and evaluations related to this problem.

\chapter{Related Work}

\cite{Beisel2023} \cite{Beisel2023a} \cite{Thullier2021}

\chapter{Methodology}
\label{chap:methodology}
\section{Conceptual Framework}
\label{sec:conceptualFramework}

This section outlines the theoretical and conceptual groundwork that anchors the methodology for this thesis.
The framework is rooted in the principles of modularity, interactivity, and interchangeability in the context of plugin-based architectures for optimization algorithms in \gls{qhana}.

\subsection{Plugin-Based Architecture in QHana}
\gls{qhana}, with its design centered on the Digital Humanities, provides an extensible platform for experimenting with various algorithms.
\gls{qhana}'s architecture predominantly revolves around the concept of RAMPs.
The objective is to leverage \gls{qhana}'s inherent modularity by enabling components of optimization algorithms to function as distinct, interchangeable plugins.
This brings us to the significance of modularity in optimization.

\subsection{Significance of Modularity in Optimization}
When \glspl{vqa} are designed with modular components, it allows for increased flexibility.
Specifically, having distinct \glspl{of} and minimization functions means parts of the algorithm can be adjusted or replaced seamlessly.
This reflects the goals of modularity and flexibility intrinsic to \gls{qhana}'s design.

\subsection{Interactivity Between Plugins}
Interactivity in \gls{qhana} should encompasses various facets:

A plugin should be able to invoke the microfrontend of another plugin.
Control should revert to the invoking plugin once the invoked plugin completes its tasks.
Both short-running tasks and long-running tasks should be facilitated.
For the latter, a callback mechanism is proposed, wherein the invoking plugin can be notified upon the completion of a long-running task by the invoked plugin.

The need for such interactivity stems from the inherent nature of optimization.
The \glspl{of} and minimization must closely interact to produce meaningful optimization results.
Moreover, since an invoking plugin is unaware of the parameters or requirements of the invoked plugin, direct interaction becomes imperative for dynamic data exchange and collaborative processing.

Drawing inspiration from existing systems, the interaction between the minimization and \glspl{of} in implementations like Scipy's \emph{optimizer.minimize} \cite{Virtanen2020} function serves as a precedent.

To elevate the degree of interactivity between plugins within \gls{qhana}, this thesis introduces the innovative concept of \emph{interaction endpoints}.
While QHana already employs a metadata field for plugins known as \emph{entry points} - endpoints invoked by the \gls{qhana} \gls{ui} to render the \gls{ui} of a plugin - interaction endpoints extend this paradigm by marking specific endpoints as callable by other plugins.

A defining characteristic of an interaction endpoint is its \emph{type}.
Interaction endpoints sharing the same type uphold uniformity in their signature and return type.
This ensures that they are invoked consistently by other plugins, irrespective of their specific implementation

\subsection{Integration and Alignment with QHana}
The proposed approach complements \gls{qhana}'s existing principles, resonating with its emphasis on extensibility, adaptability, and user-centricity.
By enhancing the interactivity and modularity of plugins within \gls{qhana}, we strive to elevate its capabilities, making it a more dynamic platform for optimization and \glspl{vqa}.

\section{Architectural Design Strategy}
\label{sec:architecturalDesignStrategy}

The architectural design process is a critical phase that dictates how the components of the solution will function and interact with each other.
The methodology undertaken for the architectural design of the plugin-based optimization framework consisted of a series of well-defined steps, ensuring clarity, modularity, and extensibility.

\subsection{Decomposition into Plugins}
The first step involved decomposing the optimization process into distinct plugins.
This is achieved by reviewing relevant literature to understand common practices and methodologies in optimization \cite{Virtanen2020, Nocedal2006, ShalevShwartz2014, Weinan2017}.
The main challenge was to find a good decomposition so that on one hand all functionalities that should be interchangeable are encompassed in an extra plugin,
on the other hand too many plugins would create an overhead that would lead to inefficiency.

\subsection{Defining Plugin Responsibilities}
Once the plugins were identified, the next step was to precisely define the responsibilities of each plugin.
This ensured that every plugin had a well-defined purpose, preventing overlaps in functionality and ensuring clarity in their roles.
To delineate these responsibilities, several crucial decisions had to be made:

\begin{itemize}
  \item Which plugin is tasked with calculating the loss function?
  \item Which one handles the minimization process?
  \item Who prompts the user for the \gls{of} hyperparameters?
  \item Who gathers the minimization function hyperparameters from the user?
  \item Who inquires about the user's preference for the \gls{of} and minimization algorithm?
  \item Who solicits the input data from the user?
  \item Who requests the target variable?
  \item And lastly, who oversees and coordinates the entire process?
\end{itemize}

\subsection{Universal Plugin Interface Design}
Recognizing the vast possibilities and variations that interchangeable plugins might encompass, it was crucial to formulate a universally adhered-to interface.
This interface acted as a "contract", ensuring that irrespective of the specific implementation details of a plugin, there existed a consistent mode of interaction.
Core attributes and functionalities, like querying the number of initial wights for the minimization process required, were defined as part of this universal interface.
This approach fostered interchangeability and adaptability, as the defined interface could accommodate a multitude of interchangeable plugins, each with its unique functionalities.
In terms of optimization, this could mean that in case of an \gls{of} plugin, that is responsible for calculating the loss function, interfaces have to be generalized to allow for any thinkable type of loss function.


\subsection{Plugin Interaction Design}
The next step was to design the interaction between plugins.
This involved defining the various ways in which plugins could interact with each other.
It was crucial to build a robust and flexible interaction design that could accommodate a multitude of scenarios, since the interaction between plugins in \gls{qhana} should not be limited to the optimization process.
This interaction design should lay the foundation for all future plugin interactions within \gls{qhana}.

Scenarios that were considered included for instance a plugin invoking the microfrontend of another plugin, or it could call a specific endpoint of another plugin.
Additionally, the interaction design also encompassed the flow of control between plugins.
For instance, a plugin could invoke another plugin and then wait for it to complete its tasks before resuming its own tasks.
A plugin could also invoke another plugin and then stop execution all together, while providing the invoked plugin with a callback URL that the invoked plugin could call once it completes its tasks.
Alternatively, a plugin could invoke another plugin and then continue with its tasks without waiting for the invoked plugin to complete its tasks.
Intrinsic to this step was also the design of a coordination mechanism that facilitated the interaction between plugins.

\subsection{UML Diagrams}
To pictorially represent the responsibilities and interfaces of each plugin, component diagrams were formulated.
A diagram encapsulated the primary tasks of a plugin and the interfaces it provides, offering a clear understanding of the system's structure.

To fathom the intricate interplay between plugins, sequence diagrams were devised.
These diagrams capture the stepwise interaction between plugins.
They detail the flow of control and data, spotlighting the sequence of plugin invocations and collaborative processes.


\subsection{Feedback and Refinement}
Throughout the design process, continuous feedback loops were integrated. This involved:
\begin{itemize}
\item Revisiting each stage, evaluating its alignment with overarching goals.
\item Making necessary refinements to ensure the architecture is both robust and flexible.
\end{itemize}

With the architectural design strategy in place, the next step is to define the implementation strategy.

\section{Implementation Strategy}
\label{sec:implementationStrategy}

\subsection{Preliminary Analysis and Design}
Before diving into the implementation, an in-depth study of the \gls{qhana} documentation and a related paper on \gls{qhana}'s architecture \cite{Buehler2022} was undertaken to gain a comprehensive understanding of the system.
With component and sequence diagrams already in place, the next step was to define the implementation strategy.

\subsection{Development Environment and Toolset}

\begin{itemize}
    \item \textbf{Visual Studio Code}: A versatile integrated development environment employed for its adaptability and support for Python development, facilitating comprehensive coding, debugging, and testing for the project.

    \item \textbf{Docker}: Utilized to run all components of \gls{qhana}, ensuring consistent behavior across different computing environments.

    \item \textbf{Postman}: An API testing tool that was employed to validate and debug various endpoints, ensuring consistent and expected behavior of the plugin interactions.

    \item \textbf{Python}: As \gls{qhana} is implemented in Python, it was the primary language for backend development, offering versatility and a vast library ecosystem.

    \item \textbf{HTML}: Used for creating the microfrontends, forming the user interfaces of the plugins.

    \item \textbf{Flask}: A lightweight Python web framework employed to develop the web services and \gls{rest}ful APIs for the plugins.

    \item \textbf{Marshmallow}: A Python library pivotal for object serialization/deserialization, ensuring structured data transfer between the plugins.

    \item \textbf{Flask-Smorest}: An extension of Flask, offering tools for building \gls{rest}ful APIs with Flask and Marshmallow, ensuring structured and accurate data transfer between plugins.

    \item \textbf{Celery}: Integrated to manage long-running tasks, particularly for objective function plugins, allowing for asynchronous task execution.

    \item \textbf{Requests}: A Python library fundamental for facilitating interactions between plugins via HTTP requests.
\end{itemize}

\subsection{Key Principles of QHana Plugins}

In the \gls{qhana} ecosystem, plugins play a pivotal role in extending functionality.
The creation and integration of these plugins are governed by a set of principles that ensure their seamless operation and interaction.
For the context of this thesis, the following principles are deemed most significant:

\begin{itemize}
    \item \textbf{Plugin Definition:}
    A plugin is essentially a Python module or package.
    It contains a class that inherits from \texttt{QHAnaPluginBase} and should be situated in a directory specified by the \texttt{PLUGIN\_FOLDERS} configuration variable.
    The plugin runner imports all plugins from these directories, handling only the root module of the plugin.
    The plugin, in turn, is responsible for importing its implementation class and all associated Celery tasks.

    \item \textbf{Plugin Metadata and Endpoints:}
    Plugins should contain metadata and links to all their endpoints, typically located in the `./` directory.
    The metadata includes crucial information like entry points.

    \item \textbf{UI Interaction:}
    Plugins define both \texttt{href} and \texttt{hrefUi} to point to their micro frontend.
    The `hrefUi` serves the microfrontend where users input data, and `href` processes this input.

    \item \textbf{Data Handling in Multi-step Plugins:}
    For plugins that necessitate multiple user input steps, data is stored in a key-value store with dictionary-like functionality.
    Data specific to a plugin task is associated with a unique database ID, and subsequent endpoint URLs of a plugin with this ID follow the pattern \texttt{http(s)://…/<UUID>/endpointName}.

    \item \textbf{Handling Long Running Tasks:}
    Long-running tasks utilize Celery. Task names, incorporating the plugin name, must be unique.

    \item \textbf{File Loading from URLs:}
    Plugins are designed to load files from URLs.

    \item \textbf{Data Format Specification:}
    Data formats, especially those shared across plugins, should be defined as per \gls{qhana}'s guidelines.
    For instance, for the \texttt{text/csv} format pertaining to entities:
    \begin{itemize}
        \item The first column must be the ID column (named ID). Subsequent columns represent entity attributes.
        \item The CSV file should contain a header row specifying all attribute names.
    \end{itemize}
\end{itemize}

It's imperative to note that while the outlined principles are crucial for this thesis, \gls{qhana}'s overarching documentation provides a more exhaustive list of best practices and guidelines for plugin creation \cite{Buehler2022}.


\subsection{Data Handling and Transfer}
Flask-Smorest was instrumental in ensuring structured and accurate data transfer between plugins.
It aided in validating the correctness of passed data, returning appropriate error codes, and managing errors efficiently.
This ensured that data exchanges between plugins, especially in the context of \glspl{vqa}, were smooth and error-free.

\subsection{Testing and Debugging}

The quality and reliability of plugins and their interactions are paramount.
For this reason, a multi-faceted testing strategy was adopted:

\begin{enumerate}
    \item \textbf{Static Code Analysis}:
    \begin{itemize}
        \item \textbf{Purpose}: To ensure code quality, maintainability, and to identify potential vulnerabilities or deviations from coding standards.
        \item \textbf{Tools \& Implementation}: The tool \texttt{flake8} was utilized to conduct static code analysis on the Python codebase.
        By running \texttt{flake8}, a report detailing any code inconsistencies, potential errors, or areas for improvement was generated, providing valuable feedback for refinement.
    \end{itemize}

    \item \textbf{Logging and Monitoring}:
    \begin{itemize}
        \item \textbf{Purpose}: To capture, store, and analyze real-time information about the system's operations, thereby aiding in troubleshooting and understanding system behavior.
        \item \textbf{Tools \& Implementation}: Python's in-built \texttt{logging} package was leveraged to track and record various events during the execution of plugins.
        By strategically placing logging statements within the code, it was possible to gain insights into the flow of operations, detect anomalies, and pinpoint areas that might require attention.
    \end{itemize}

    \item \textbf{Interactive Debugging}:
    \begin{itemize}
        \item \textbf{Purpose}: To step through the code in real-time, inspect variables, and analyze the program's flow to identify and rectify issues.
        \item \textbf{Tools \& Implementation}: The integrated Python debugger in Visual Studio Code was employed.
        This debugger allowed for setting breakpoints, stepping through code, inspecting variable states, and examining the call stack, providing a granular view of the system's operations and aiding in issue identification and resolution.
    \end{itemize}

    \item \textbf{Manual Testing}:
    \begin{itemize}
        \item \textbf{Purpose}: To capture nuances and potential issues that might be overlooked.
        \item \textbf{Procedure}: A hands-on approach was adopted where the plugins were interactively used.
        This involved navigating through the \gls{ui}, experimenting with different inputs, and observing the system's reactions to ensure it behaved as expected and met user requirements.
    \end{itemize}
\end{enumerate}

By employing a combination of static code analysis, detailed logging, interactive debugging, and manual testing, it was ensured that the plugins were not only functionally correct but also adhered to coding standards and best practices, guaranteeing a robust and user-friendly experience.


\subsection{Performance Optimization}
For optimal performance in the microservice-based plugin architecture, several strategies were employed:

\begin{enumerate}
    \item Reducing the number of interactions between plugins.
    \item For each interaction, the amount of data transmitted across the network should be kept to a minimum to ensure efficient communication and faster response times.
    \item For tasks that require extended processing, the Celery framework should be utilized, allowing these tasks to operate asynchronously and thereby optimizing resource usage.
\end{enumerate}

These strategies were critical in ensuring swift and seamless interactions between plugins.


\subsection{Documentation and Extensibility}
To foster an environment of growth and encourage future development, comprehensive documentation detailing the process of adding new \gls{of} and minimization plugins was created.
This documentation serves as a guideline for developers aiming to extend the capabilities of \gls{qhana} with plugin interaction.


\section{Evaluation Strategy}
\label{sec:evaluationStrategy}

The implementation section of this thesis will ultimately present two distinct versions of a plugin-based optimization framework.
The evaluation will assess both versions to facilitate a comparison between the two approaches.
Additionally, the evaluation will juxtapose these approaches with a non-plugin-based approach, presented in the form of a Jupyter notebook.
To validate the effectiveness of the proposed solutions and to assess whether the goals set out in the problem statement have been achieved, the following evaluation methodologies are adopted:

\subsection{Performance Benchmarking}
Performance is paramount, especially in a plugin-based architecture.
A direct comparison will be made between the two plugin-based approaches and the non-service-based approach.
Key metrics for this comparison include:

\begin{itemize}
\item \textbf{Objective Function Calculation Time}: This measures the time taken to compute the loss, which directly impacts the overall optimization time.
For the service-based approach, the evaluation encompasses not only the calculation time of the \gls{of} but also the time taken for a call to the \gls{of} calculation endpoint.

\item \textbf{Minimization Time}: This refers to the time consumed to minimize the \gls{of}.
In the service-based approach, the time taken for the minimization endpoint to return a result is also accounted for.

\item \textbf{Network Latency}: This quantifies the time required for a request to reach the server and for the corresponding response to be received.
This metric is exclusive to the service-based approach.

\item \textbf{Network Traffic}: This represents the volume of data transmitted between the endpoints.
This metric is exclusive to the service-based approach.

\item \textbf{Database Access Times}: It is essential to gauge the time required to retrieve data from the database since endpoints access context data from the database during each invocation.
\end{itemize}

This evaluation hinges on quantitative metrics, with results graphically depicted for enhanced clarity.
The \emph{time.perf\_count} function from Python is employed to capture measurements, while the Google Chrome developer tools are used to measure network traffic.

\subsection{Interchangeability}
The true measure of interchangeability is the ability to swap components without causing disruptions.
Accordingly, every plugin of a particular type is tested against every other plugin of the same type to validate seamless interchangeability.

\subsection{Standardization Adherence}
Standardization, pivotal for ensuring compatibility and uniformity across diverse plugins, is put to the test.
An evaluation is undertaken to determine whether all implemented plugins conform to the prescribed standards.
This guarantees that all optimization plugins can be implemented uniformly, facilitating consistent and compatible integrations in the future.

\subsection{User Experience}
While the primary audience for this thesis is developers for the \gls{qhana} platform, the user experience is not to be undermined.
An assessment determines the ease and efficiency with which a developer can introduce a new plugin in the context of service-based optimization in \gls{qhana}.
The complexity and the lines of code required to integrate a new, interchangeable plugin for the optimization process are enumerated and compared across the approaches.

Through a meticulous evaluation across these parameters, this thesis endeavors to furnish a thorough appraisal of the solutions in relation to the challenges delineated in the problem statement.\section{Test Data Generation for Evaluation}

To robustly evaluate the solutions proposed in this work, it's essential to test them on a diverse range of datasets, reflecting both size and complexity.
The objective is to mimic real-world scenarios where optimization problems can range from simple tasks with a few data points to complex challenges with a vast number of features and data points.
The code that was used to generate the test data can be found in the appendix \ref{appendix:generate_data}.

\subsection{Dataset Characteristics:}

\begin{enumerate}
    \item \textbf{Variability in Size}: Datasets of different sizes have been generated, spanning from a modest 10 data points to a substantial 100,000 data points.
    This variation ensures that the optimization performance is assessed across different scales, from quick-to-process small datasets to the computationally demanding large datasets.

    \item \textbf{Features Determined by Size}: The number of features, \( x \), in each dataset is dynamically determined based on the dataset's size, specifically calculated as \( \text{int}(\sqrt{\text{size}} \times 1.5) \).
    This approach ensures that with the growth of the dataset, its complexity also increases, mirroring real-world scenarios where larger datasets often present more features or dimensions.

    \item \textbf{Synthetic Data with Noise}: The data is synthetically generated using the \texttt{make\_regression} function from the Scikit-learn library, known for its utility in machine learning.
    An added noise parameter introduces an element of randomness, making the optimization task more intricate and thereby closely resembling real-world challenges.

    \item \textbf{Ensuring Reproducibility}: To maintain the consistency and reliability of the generated datasets across multiple runs or evaluations, a fixed random seed (`np.random.seed(42)`) has been set.
    This ensures that the data, though synthetic and noisy, remains consistent across evaluations, enabling true comparisons, assessments and reproducibility.

    \item \textbf{Adherence to QHana Standards}:
   \begin{itemize}
        \item \textbf{Unique Entity IDs}: Each data point in the dataset is allocated a unique ID in the format 'entityX', where X represents the entity number. This aligns with \gls{qhana}'s data standard that mandates every data point to have an identifiable ID.
        \item \textbf{Data Format and Storage}: All datasets are stored in the CSV (Comma Separated Values) format, adhering to \gls{qhana}'s accepted data formats.
    \end{itemize}
\end{enumerate}

By employing such multifaceted and representative datasets, the methodology aims to guarantee a holistic evaluation of the optimization solutions, assessing their performance, interchangeability, and user experience across a diverse range of scenarios.

\chapter{Resutling System Architecture}
\label{chap:architecture}


\section{Resutant Decompostion into Plugins and their Responsibilities}

Following the decomposition strategy, the plugin-based optimization framework was divided into three primary plugin types:
\gls{of} plugin, the minimizer plugin, and the coorinator plugin.
Each of these plugins was equipped with specific roles and responsibilities, ensuring a modular and efficient optimization process.
This split is visualized in the component diagram in figure \ref{fig:component_diagram}.
It is important to note that for both proposed plugin-based approaches, this decomposition and the associated responsibilities remain consistent.

\subsection{Objective Function Plugin}

The \gls{of} plugin is central to the optimization framework, encapsulating the mathematical function that defines the problem at hand.
Its primary roles include:

\begin{itemize}
\item \textbf{Metadata Provision}: The plugin offers metadata about itself.
\item \textbf{Hyperparameters Acquisition}: It prompts the user to provide the hyperparameters necessary for the loss function calculation.
\item \textbf{Loss Calculation}: Based on the provided input data, the plugin computes the loss, representing the discrepancy between the predicted values and actual values.
\item \textbf{Gradient Calculation (Optional)}: For optimization algorithms that leverage gradient-based methods, the plugin can optionally compute the gradient of the loss function. This aids in guiding the optimization process towards the desired minima.
\end{itemize}

\subsection{Minimizer Plugin}

The minimizer plugin is responsible for iteratively adjusting parameters to minimize the loss provided by the Objective Function plugin.
Its functions include:

\begin{itemize}
\item \textbf{Metadata Provision}: Similar to the \gls{of} plugin, it provides essential metadata.
\item \textbf{Hyperparameters Acquisition}: The plugin acquires the hyperparameters crucial for the employed minimization algorithm from the user.
\item \textbf{Minimization Process}: Using the loss (and optionally the gradient) from the \gls{of} plugin, the minimizer plugin endeavors to find the parameter values that minimize this loss.
\end{itemize}

\subsection{Coordinator Plugin}

The Coordinator plugin acts as the orchestrator, ensuring seamless interaction between the \gls{of} and Minimization plugins and the user.
Its primary responsibilities are:

\begin{itemize}
\item \textbf{Plugin Selection}: It prompts the user to select the desired \gls{of} and minimizer plugins to be used in the optimization process.
\item \textbf{Data Acquisition}: The plugin gathers the necessary input data and the target variable from the user, which will be used in the optimization process.
\item \textbf{Endpoint Acquisition}: It obtains the necessary endpoints from the selected plugins, which will be used for interaction.
\item \textbf{Coordination Role}: It manages the interaction between the \gls{of} and minimizer plugins, ensuring that the loss (and optionally gradient) calculation function is provided to the minimizer plugin for the optimization process.
Additionally, it coordinates the interaction between the user and the selected plugins, ensuring the user is provided with the necessary microfrontends.
\item \textbf{Results Presentation}: Post-optimization, the coordinator plugin presents the optimization results to the user.
\end{itemize}


\section{Universal Plugin Interface Design}

The process of optimization is inherently complex, with a multitude of variations and nuances.
To ensure a streamlined interaction between different plugins, it was imperative to establish universal plugin interfaces for each type of plugin.
This interface acts as a standard that every plugin of a specific type has to adhere to.
The interfaces for each plugin are detailed below and are visualized in the component diagram in figure \ref{fig:component_diagram}.

\subsection{Objective Function Plugin Interfaces}

The \gls{of} plugin interface is designed to accommodate a wide range of loss functions, including those that require gradient computation.
Its interfaces are:

\begin{itemize}
\item \textbf{Metadata}: The plugin provides metadata about itself as specified in the \gls{qhana} documentation \cite{Buehler2022}.
\item \textbf{UIRef}: This endpoint is used to obtain the microfrontend for the \gls{of} plugin, which is used to collect the hyperparameters from the user.
This interface is also in accordance with the \gls{qhana} documentation \cite{Buehler2022}.
\item \textbf{HRef}: This endpoint is used to process the input from the \gls{of} microfrontend.
It is usually triggered by the user clicking the \emph{submit} button on the microfrontend.
This interface is also in accordance with the \gls{qhana} documentation \cite{Buehler2022}.
\item \textbf{PassData}: This endpoint is used to pass the input data and the target data to the \gls{of} plugin.
It returns the number of weights that is required for the optimization process.
The number of weights is returned here since it is depandant on the data and possibly the hyperparameters.
\item \textbf{CalculateLoss}: This endpoint is used to calculate the loss.
\item \textbf{CalculateGradient}: This endpoint is used to calculate the gradient of the loss function.
\item \textbf{CalculateLossAndGradient}: This endpoint is used to calculate the loss and the gradient of the loss function.
\end{itemize}

\subsection{Minimizer Plugin Interfaces}

The minimizer plugin, responsible for optimizing the loss function provided by the \gls{of} plugin, offers these interfaces:

\begin{itemize}
  \item \textbf{Metadata}: same as for the \gls{of} plugin
  \item \textbf{UIRef}: same as for the \gls{of} plugin
  \item \textbf{HRef}: same as for the \gls{of} plugin
  \item \textbf{Minimize}: This endpoint is used to minimize the loss function.
\end{itemize}

\subsection{Coordinator Plugin Interfaces}

The Coordinator plugin, orchestrating the interaction between the OF and Minimizer plugins, is equipped with the standard \gls{qhana} interfaces \textbf{Metadata}, \textbf{UIRef}, and \textbf{HRef}.

By establishing these interfaces and ensuring that each plugin conforms to them, a systematic, consistent, and efficient optimization process is ensured.
This structured approach not only facilitates seamless interactions but also fosters interchangeability, modularity, extensibility and Interchangeability and making it easy to add new \gls{of} and minimizer plugins in the future.

\section{Plugin Interaction Design}

The design of plugin interactions is pivotal to ensuring efficient and seamless coordination between different components of the system. Given the extensive possibilities of interactions within the \gls{qhana} environment, the design phase was meticulous, taking into consideration various scenarios and ensuring adaptability. The two primary modes of interactions were short-running and long-running, each catering to specific requirements.

\subsection{Short-Running Interaction}

In short-running interactions, a plugin invokes another plugin's endpoint, typically via a `GET` or a `Post` request, and immediately receives a response.
This mode of interaction is synchronous, wherein the invoking plugin waits for the response before proceeding. Instances of such interactions include:
\begin{itemize}
    \item The coordinator plugin retrieving metadata of an invokable plugin.
    \item The coordinator plugin passing data to the \gls{of} plugin.
    \item The minimizer plugin calling the \texttt{CalculateLoss} endpoint of the \gls{of} plugin.
\end{itemize}

\subsubsection{Long-Running Interaction}

For processes that demand extensive computation time or involve multiple steps, long-running interactions come into play.
In such a case the calling plugin invokes the endpoint of the invoked plugin.
This endodpoint return immediately indicating that is has successfully triggred the long-running process.
The invoking plugin then continues with its tasks.
Since the invoking plugin usually needs the result of the long-running process, a callback mechanism is introduced.
These interactions are  and can be further divided into two categories:

\paragraph{Multiple Short-Running Endpoints:}
\begin{itemize}
    \item \textbf{Scenario:} The coordinator plugin invokes the microfrontend of the \gls{of} plugin, which returns instantly.
    However, upon user input, the \texttt{href} endpoint of the \gls{of} plugin is triggered, and only upon its completion is control reverted to the coordinator.
    \item \textbf{Mechanism:} The invoking plugin provides a callback URL during the initial call.
    This callback URL is propagated through all subsequent endpoints.
    Once the final endpoint completes its task, it issues a request to the callback URL, effectively notifying the invoking plugin of task completion.
    Any necessary response data is appended by the last endpoint in this chain.
\end{itemize}

\paragraph{Asynchronous Tasks:}
\begin{itemize}
    \item \textbf{Scenario:} The coordinator plugin triggers the minimization endpoint of the minimizer plugin, a process that could involve one or multiple asynchronous long running tasks.
    \item \textbf{Mechanism:} As with the previous category, a callback endpoint on the invoking side is created and passed to the invoked plugin in the form of a URL.
    The invoked plugin then triggers the asynchronous task and returns immediately.
    Upon completion of the asynchronous task, QHana's inherent property of updating the database with task status is leveraged.
    A signaling mechanism is introduced to detect the status change to 'finished', triggering a function that calls the provided callback URL.
    Crucially, any results from the long-running process are encapsulated within QHana's task view.
    An URL pointing to these results is then shared with the invoking plugin for further processing or display.
\end{itemize}

The design of these interactions ensures that regardless of the complexity or duration of tasks, plugins can interact seamlessly, efficiently, and adaptably.

\section{Introduction of Interaction Endpoints}
\label{sec:introie}

Building upon the idea of plugins interacting with each other, as detailed in the previous section, there arises a crucial question:
How does one plugin discover the available endpoints of another?
To address this very challenge, this thesis introduces a novel concept called \textit{interaction endpoints} to \gls{qhana}.

While \gls{qhana} already has a metadata field named `entry points', which are endpoints invoked by the \gls{qhana} UI to render a plugin's UI, interaction endpoints extend this idea further.
They specifically define endpoints in the metadata that other plugins can invoke, facilitating seamless integration and interaction among them.

The core of interaction endpoints is their \emph{type}.
All interaction endpoints with the same type must adhere to the same signature and return type.
This uniformity ensures that they can be interchangeably invoked by other plugins.
The \gls{of} plugin provides interaction endpoints of types \emph{calc\_loss}, \emph{calc\_grad}, \emph{calc\_loss\_and\_grad}, and \emph{of\_pass\_data}.
The minimizer plugin offers the `minimization' type.
These interaction endpoints correspond to the endpoints defined in the previous section.
The introduction of interaction endpoints significantly enhances the modularity and interchangeability within \gls{qhana}, paving the way for a more dynamic and adaptable plugin ecosystem.

Below are the detailed specifications for these interaction endpoints:

\begin{description}
    \item[minimization]
    \begin{itemize}
        \item \textbf{Arguments:}
        \begin{description}
            \item[Required:] initial weights, URL to \emph{CalculateLoss} endpoint
            \item[Optional:] URL to \emph{CalculateGradient}, URL to \emph{CalculateLossAndGradient}, URL to callback enpoint of invoking plugin, x, y
        \end{description}
        \item \textbf{Returns:} URL to \gls{qhana}'s task view for the asynchronous task
    \end{itemize}

    \item[calc\_loss]
    \begin{itemize}
        \item \textbf{Arguments:}
        \begin{description}
            \item[Required:] weights for the loss function
            \item[Optional:] x, y
        \end{description}
        \item \textbf{Returns:} loss value
    \end{itemize}

    \item[calc\_grad]
    \begin{itemize}
        \item \textbf{Arguments:}
        \begin{description}
            \item[Required:] weights for the loss function
            \item[Optional:] x, y
        \end{description}
        \item \textbf{Returns:} gradient of the loss function
    \end{itemize}

    \item[calc\_loss\_and\_grad]
    \begin{itemize}
        \item \textbf{Arguments:}
        \begin{description}
            \item[Required:] weights for the loss function
            \item[Optional:] x, y
        \end{description}
        \item \textbf{Returns:} loss value, gradient of the loss function
    \end{itemize}

    \item[of\_pass\_data]
    \begin{itemize}
        \item \textbf{Arguments:}
        \begin{description}
            \item[Required:] x, y
        \end{description}
        \item \textbf{Returns:} number of required weights for the loss function
    \end{itemize}
\end{description}

The key difference between the two proposed service-based approaches is the optional arguments \emph{x} and \emph{y} of the \emph{calc\_loss}, \emph{calc\_grad}, \emph{calc\_loss\_and\_grad}, and \emph{minimize} interaction endpoints, where for one approach these arguemtns are required and for the other they are optional.

\section{Final Interaction Flow}
With the architecture now fully defined, the final interaction flow can be visualized.
Figure \ref{fig:interaction_flow} shows the interaction flow for the two proposed approaches.


\chapter{Implementation}
\label{chap:implementation}

In this chapter, we delve into the practicalities of realizing the architectural design, focusing on the actual implementation.
The first part is on the implementation of the \glspl{ui} for the plugins.

\section{Leveraging QHAna for UI Creation}
The QHAna platform provides a streamlined mechanism to craft simple UIs with input fields, generated from marshmallow schemas.
The primary step is to inherit from QHAna's \texttt{FrontendFormBaseSchema} class.
This ensures that the \gls{ui} aligns with the platform's standards and practices while still providing the flexibility to define plugin-specific inputs.
For the \gls{of} plugin, the user inputs the hyperparameters needed by the loss function.
The minimizer plugin's UI is concerned with the choice hyperparameters for the minimization function.
The coordinator plugin's UI acts as a control center.
It facilitates the selection of the appropriate \gls{of} and minimizer plugins, the dataset of interest, and the specific target variable within that dataset.

The code in \ref{lst:coordinator_schema} demonstates how such a schema is defined for the coordinator plugin.
This example shows the how one would define such an input schema for a sting, a file and a plugin.
A noteworthy feature is the utilization of the \emph{PluginUrl} class plugin selection fields
This custom class, which extends marshmallow's \emph{fields.Url} class, ensures that users can only select plugins that align with the required type.
However, this also means that it's imperative for plugins to have their metadata accurately labeled with the correct type to ensure seamless integration.

\lstinputlisting[language=Python, caption=Coordinator Plugin UI Schema., label=lst:coordinator_schema]{code/ui_schema_coordinator.py}.

\section{Implementation of Plugin Endpoints}
\label{sec:implementationOfInteractionEndpoints}

\subsection{Custom Marshmallow Field for Data}
\label{sec:customMarshmallowFieldForData}
In order to facilitate the passing of input and target data between plugins, a custom marshmallow field was developed.
This field, named \emph{NumpyArray} and shown in \ref{lst:numpy_array_schema}, is designed to handle numpy arrays.
This field is able to handle numpy arrays of any dimensionality and any data type that is json serializable.
Not only is this field used for passing the data between endpoints but also for storing the data effectively in the database.
\lstinputlisting[language=Python, caption=Custom Marshmallow Field for Numpy Arrays., label=lst:numpy_array_schema]{code/numpy_array_schema.py}.


\section{Implementation of Interaction Endpoints}
\label{sec:implementationOfInteractionEndpointMetadata}
interaction endpoints are now part of teh metatada of plugins.
since the url of plugin endpoints include the database id interaction endpoints also have to be aware of the database id of the plugin
since the database id is not yet known when the metadata is created interaction endpoint url are defined as format strings
to make it easier for developers the types of interactions endpoints are defined as enums as can be seen in \ref{lst:interaction_endpoint_types}
For the of pluing that implements ridge loss for example the interactoin endpoint defintions can look like depicted in
the \emph{url\_for} method call creates the base url for the plugin and the rest of the endpoint url is concated to that base url
\lstinputlisting[language=Python, caption=Enum for Interaction Endpoint Types., label=lst:interaction_endpoint_types]{code/interaction_endpoint_types.py}.
\lstinputlisting[language=Python, caption=Interaction Endpoint Metadata for the Ridge Loss OF Plugin., label=lst:ridge_loss_interaction_endpoint_metadata]{code/interaction_endpoints_of.py}.

The arugments passed to the interaction endpoints and returned by the interaction enpoints are defined as marshmallow schemas in the shared folder.
For the \emph{calc\_loss} endpoint where the arguments are the weights for the loss function and optionally the input data and the target data and the return value is the loss value the schema looks like shown in \ref{lst:calc_loss_schema}.

\lstinputlisting[language=Python, caption=Schema for the calc\_loss Interaction Endpoint., label=lst:calc_loss_schema]{code/calc_loss_schema.py}.

\section{Implementation differences between the two approaches}
the two approaches differ in the way the input and target data is passed to the of plugins calc\_loss endpoint
in one approach the data is passed to the of\_pass\_data endpoint of the \gls{of} plugin and there the data is stored in the database
in when caluculating the loss in the calc\_loss endpoint the data is loaded from the database and used to calculate the loss

in the other approach the data is passed directly to the calc\_loss endpoint by the minimizer plugin and not loaded from the database
that means that the coordinator plugin also has to pass the data to the minimizers minimize endpoint


* with callback endpoints and stuff

data is shared across pluings endpoints via db and uuids

interactions enpoitns are defined in the metadata of the plugins as format strings
the format strings are then filled with the uuids of the plugins once the plugins ui was finished, the processing enpoint returns the uuids of the plugins

introduction of numpy array format in marshmallow

difference between the two approaches lies in the interaction between the of calc endpoint and the minimization Endpoint
in one the data itself it not passed to the calc\_loss enpoint but instead the data is loaded from the db in the calc\_loss endpoint
in the other approach the data is passed to the calc\_loss endpoint and not loaded from the db

what final methods the objective function plugin has
what final methods the minimizer plugin has

then we do show example implementations
these are the two minimizers grad and no grad
and the three ob function ridge, hinge, and nn

\section{Directory Structure and Plugin Loading}
\label{sec:directoryStructure}

\gls{qhana} maintains two primary directories for plugin management: the \textit{plugins} and the \textit{stable plugins} directories.
The former hosts plugins undergoing development, while the latter contains plugins that are deployment-ready.
Within these directories, individual plugins are neatly organized into dedicated subfolders.
Upon initiation, \gls{qhana} scans and loads plugins from these designated subfolders.

The focus of this thesis, the optimization plugin, resides in the \textit{plugins/optimization} directory.
To promote clarity and a structured layout, further divisions were made:

\begin{itemize}
  \item \textit{plugins/optimization/coordinator} – For the main optimization plugin.
  \item \textit{plugins/optimization/objective\_functions} – Where each \gls{of} plugin occupies its respective subfolder.
  \item \textit{plugins/optimization/minimizer} – Where each minimizer plugin occupies its respective subfolder.
\end{itemize}

Given that \gls{qhana}'s native architecture does not support the direct loading of plugins from nested subdirectories, a recursive plugin loader was developed for this purpose.
This loader traverses through the \textit{plugins} directory and its subdirectories.
The presence of an \textit{\_\_init\_\_.py} file within a folder acts as a confirmation for the plugin's legitimacy.
If any plugin needs to be excluded from the loading process, a \textit{.ignore} file is placed in its respective folder to act as a loading deterrent.

To ensure that the recursive process doesn’t compromise system performance, the recursion depth is capped at 4.
This threshold sufficiently accommodates the current plugin structure but can be adjusted upwards if future needs arise.

The folder hierarchy is further enriched by the inclusion of an \textit{interaction\_utils} directory, dedicated to housing utility functions for generalized plugin interactions.
Additionally, there's a \textit{shared} directory, which stores data structures and schemas utilized across the plugins related to optimization plugin.
A visual representation of the final folder structure, with all plugins implemented for this thesis, is shown in \cref{fig:folderStructure}.


\begin{figure}[h!]
  \dirtree{%
      .1 plugins.
      .2 optimizer.
      .3 coordinator.
      .3 interaction\_utils.
      .3 minimizer.
      .4 scipy\_minimizer.
      .4 scipy\_minimizer\_grad.
      .3 objective\_functions.
      .4 hinge\_loss.
      .4 neural\_network.
      .4 ridge\_loss.
      .3 shared.
  }
  \caption{QHana Plugin Folder Structure.}
  \label{fig:folderStructure}
\end{figure}


\section{Interaction Endpoints}
\label{sec:interactionEndpoints}
this thesis introduces the concept of interaction endpoints to \gls{qhana}
qhana already defines a metadata field for pluings called entry points which are edndpoints called by the qhana ui to render the ui of a plugin
interaction endpoints add to this conecpt by defining endpoints that are callable by other plugins
an interaction endoint has a type.
all interaction endpoints which the same type must have the same signature and return type and can be called in the same way by other plugins
in the case of of objective function plugins for example one interaction endpoint type is the \emph{objectivefunctioncalc} type which is used to calculate the loss function
all plugins that have this type of interaction endpoint can be used as an objective function plugin

this concept has several advantages
* it allows for full interchangeability of plugins
* it allows the developer that want to interact with a plugin to know what endpoints are available and how to call them
* an alternatiev would be to return the url of available endpoitns after passing through the ui, now we can completely skip the ui alltogether and just call the endpoint directly


\section{Implementation of an Objective Function Plugin}
\label{sec:implementationOfAnObjectiveFunctionPlugin}

to go over the taks of an of plugin again:
* parameter acquisition
* loss computation
* loss return

\subsection{Parameter Acquisition}
\label{subsec:parameterAcquisition}
parameter acquisition is done via an ui that is rendered by the plugin.
the ui is no new concept but follows the standard concept of an microfrontend in qhana
it presents the user with a form that is defined in a marshmallow schema
that schema holds the hyperparameters of the of plugin
in case of a ridge loss plugin this hyperparameter is the alpha value as described in the background section
when clicking submit the ui makes a post request to the processing endpoint of the plugin
this processing endpoint saves the hyperparameters to the database and makes a post

to allow for interaction between plugins the ui has some additional functionality
since it is a invocable plugin a callback url to and invoking plugin endpoint is passed to the ui via a query parameter
it is a query parameter since the has to be called with an get request and get requests can only have query parameters
the ui endpoint forwards the callback url to the processing endpoint of the of plugin as a query parameter
the processing endpoint then makes a post request to the callback url when it is done with its setup

\subsection{Objective Function interaction endpoints}
\label{subsec:objectiveFunctionInteractionEndpoints}
the of plugin should provide several interaction endpoints
on is the pass data endpoint
this endpoint is called to pass input data to the of plugin
there are several reasons why this is done via an interaction endpoint and not via ui input
* the data is not specific to the of plugin but is shared between the of plugin and the min plugin, so therefore the user should not have to enter it here but rather in the coordinator plugin
* one could think that the cooridnator plugin could just pass the data to the of plugin via the ui endpoint, but this would mean passing huge ammonts of data via a get request which is not a good idea
* one could think about passing a link to a file that contains the data, but this would mean that the of plugin would have to download the file and parse it, this should not be the job of the of plugin
* the minimization plugin could pass the data to the of plugin when calling the of plugin to calculate the loss, but this would mean that one the min pluing needs to know the data, which otherwise is not necessary, 2. the min plugin would have to pass the data to the of plugin every time it calls the of plugin to calculate the loss, which would cause a lot of network traffic, 3. it would make the process less generic, since the min plugin would have to know how to pass the data to the of plugin

this endpoint can simply be called by a invoking plugin via a post request and returns directly after saving the data to the database
this endpoint also returns the metadata numberofweights which is the number of weights that the of plugin needs to calculate the loss function
this is needed by a minimization plugin to know how many weights it needs to pass to the of plugin when calling the of plugin to calculate the loss function
the number of weights is passed here since it is can depend on the data and the of hyperparameters and therefore is not known when the metadata is requested

one interaction endpoint is the loss fucntion calculation endpoint
this endpoint is called to calculate the loss function
it can be called by a invoking plugin via a post request
the arugments passed to the endpoints are the weights of the model
the endpoint then calculates the loss function and returns it

an optinal interaction endpoint is the gradient calculation endpoint
this endpoint is called to calculate the gradient of the loss function
it can be called by a invoking plugin via a post request
the arugments passed to the endpoints are the weights of the model
the endpoint then calculates the gradient of the loss function and returns it

another optional interaction endpoitn is the gradient and loss function calculation endpoint
this endpoint combined the two previous endpoints into one since the loss function and the gradient of the loss function are often calculated together and so makes the process more efficient
it can be called by a invoking plugin via a post request
the arugments passed to the endpoints are the weights of the model
the endpoint then calculates the loss function and the gradient of the loss function and returns them


\section{Implementation of a Minimization Function Plugin}
\label{sec:implementationOfAMinimizationFunctionPlugin}
to go over the taks of an min plugin again:
* parameter acquisition
* function minimization
* result return

\subsection{Parameter Acquisition}
\label{subsec:parameterAcquisition}
parameter acquisition is done the same way as for the of plugin
as an example for the min plugin that uses the scipy minimize function the hyperparameter is the method that is used to minimize the function

\subsection{Minimization Function interaction endpoints}
\label{subsec:minimizationFunctionInteractionEndpoints}

a minimization plugin provides a single interaction endpoint
this endpoint is called to minimize the of
the arugments passed to the endpoints is the url of the of plugin loss calculation endpoint, the weights of the model, and a callback url to the invoking plugin
some optinal arguments can be the url of the of plugin gradient calculation endpoint and the url of the of plugin gradient and loss function calculation endpoint
these optional arguments are only considrered if the minimization plugin implements a minimization function that uses the gradient of the loss function
the endpoint schedules an asyncronous celery task that minimizes the of
it return directly after scheduling the task

the celery task minimizes the of by calling the calcucation endpoint over and over again
a novel approach is used to make a callback to the invoking plugin
qhana provides a way url to an celery task of a plugin that can be called to get the status of the task
this status is stored in a database
the python library blinker is used to to track changes to the status of the task
now when the status of a task changes the blinker library calls a function that is registered to the status change event
this function then makes a post request to the callback url of the invoking plugin
this way the invoking plugin is notified when the task is done and does not have to poll the status of the task

\section{Implementation of a Coordinator Plugin}

\section{Plugin Infrastructure}
\label{sec:pluginInfrastructure}
\section{Plugin Interaction}
\label{sec:pluginInteraction}
\section{Minimizer Plugin}
\label{sec:minimizerPlugin}
\section{Objective Function Plugins}
\label{sec:objectiveFunctionPlugins}


\chapter{Evaluation}
\label{chap:evaluation}
\section{Sample Machine Learning Experiment}
\label{sec:sampleMachineLearningExperiment}
\section{Interchangeability of Plugins}
\label{sec:interchangeabilityOfPlugins}
\section{Performance Analysis}
\label{sec:performanceAnalysis}

The performance of the system is evaluated by measuring the time the system takes to complete a machine learning experiment.
The time that it takes for a user to input the data is not measured.
This benchmark should only measure the time that it takes for the system to complete the experiment.
We compare the performance of the plugin based system with the performance of a jupyter notebook based system.
There are several steps that are benchmarked in the plugin based system, since there is user interaction between the steps.
\begin{itemize}
  \item The time that it takes after the user has selected the plugins until the user can input the hyperparameters for the of plugin.
  \item The time that it takes after the user has input the of plugin hyperparameters until the user can input the hyperparameters for the minimizer plugin.
  \item The time that it takes after the user has input the minimizer plugin hyperparameters until the user gets the result of the experiment.
\end{itemize}
The times of those steps are summed up to get the total time that it takes for the plugin based system to complete the experiment.
The time that it takes for the jupyter notebook based system is measured from the start of the notebook until the user gets the result of the experiment.
The time is measured by adding a timestamp at the start of the step and at the end of the step.
The difference between the two timestamps is the time that it takes for the step to complete.
The time that it takes for the plugin based system to complete the experiment is compared to the time that it takes for the jupyter notebook based system to complete the experiment.
In order to get a more accurate result, the experiment is repeated several times and the average time is taken.
To make it as comparable as possible, the same datasets and hyperparameters are used for both systems.
The output file of the experiment should also have the same exact format.

Since the benchmark of the plugin based system shows worse performance than the jupyter notebook based system, we want to explore where the most time is spent.
Therefore, we measure the time it takes to call to calculate the loss function.
In case of the plugin based system this includes the network latency between the plugins.
We want to see how much time is spent in the network and how much time is spent in the actual calculation of the loss function.

For more sophisticated loss functions (in this case the neural network) we want to see how much time is spent for the setup of the neural network.
Since a microservice does not have state, the neural network has to be setup for every call of to calculate loss function.

\section{Hardware and System Specifications}

The benchmarks were conducted on a MacBook Pro. The detailed specifications of the machine are as follows:

\begin{itemize}
    \item \textbf{Model:} MacBookPro18,1
    \item \textbf{Processor (CPU):} Apple M1 Pro
    \item \textbf{Memory (RAM):} 32 GB (hw.memsize: 34359738368 bytes)
    \item \textbf{Graphics Processing Unit (GPU):}
    \begin{itemize}
        \item Chipset Model: Apple M1 Pro
        \item Type: GPU
        \item Bus: Built-In
        \item Total Number of Cores: 16
        \item Metal Support: Metal 3
    \end{itemize}
    \item \textbf{Operating System:} macOS, Version 13.4.1, Build Version: 22F770820d
\end{itemize}


\section{Accuracy Analysis}
\label{sec:accuracyAnalysis}
In terms of accuracy we compare the results of the plugin based system with the results of the jupyter notebook based system.
The results of the two systems should be the same, since the same datasets and hyperparameters are used.
Also, we should see the same results since the same actual code is executed in both systems, only the way of calling the code is different.
The results are compared by calculating the mean squared error between the two results.



\chapter{Discussion}
\label{chap:discussion}
\section{Achievements and Contribution}
\label{sec:achievementsAndContribution}
\section{Limitations}
\label{sec:limitations}


\chapter{Conclusion and Outlook}
\label{chap:zusfas}

\section{Outlook}

\printbibliography

All links were last followed on October 15, 2023.

\appendix

\pagestyle{empty}
\renewcommand*{\chapterpagestyle}{empty}
\Versicherung
\end{document}
